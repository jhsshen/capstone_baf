{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Load previously processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediate data was saved as '../data/baf_cat_dummy_na_median_num_scaled.csv.gz' previously.\n",
    "baf_data = pd.read_csv('../data/baf_cat_dummy_na_median_num_scaled.csv.gz', compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 993563 entries, 0 to 993562\n",
      "Data columns (total 53 columns):\n",
      " #   Column                            Non-Null Count   Dtype  \n",
      "---  ------                            --------------   -----  \n",
      " 0   fraud_bool                        993563 non-null  int64  \n",
      " 1   email_is_free                     993563 non-null  int64  \n",
      " 2   phone_home_valid                  993563 non-null  int64  \n",
      " 3   phone_mobile_valid                993563 non-null  int64  \n",
      " 4   has_other_cards                   993563 non-null  int64  \n",
      " 5   foreign_request                   993563 non-null  int64  \n",
      " 6   keep_alive_session                993563 non-null  int64  \n",
      " 7   payment_type_AA                   993563 non-null  int64  \n",
      " 8   payment_type_AB                   993563 non-null  int64  \n",
      " 9   payment_type_AC                   993563 non-null  int64  \n",
      " 10  payment_type_AD                   993563 non-null  int64  \n",
      " 11  payment_type_AE                   993563 non-null  int64  \n",
      " 12  employment_status_CA              993563 non-null  int64  \n",
      " 13  employment_status_CB              993563 non-null  int64  \n",
      " 14  employment_status_CC              993563 non-null  int64  \n",
      " 15  employment_status_CD              993563 non-null  int64  \n",
      " 16  employment_status_CE              993563 non-null  int64  \n",
      " 17  employment_status_CF              993563 non-null  int64  \n",
      " 18  employment_status_CG              993563 non-null  int64  \n",
      " 19  housing_status_BA                 993563 non-null  int64  \n",
      " 20  housing_status_BB                 993563 non-null  int64  \n",
      " 21  housing_status_BC                 993563 non-null  int64  \n",
      " 22  housing_status_BD                 993563 non-null  int64  \n",
      " 23  housing_status_BE                 993563 non-null  int64  \n",
      " 24  housing_status_BF                 993563 non-null  int64  \n",
      " 25  housing_status_BG                 993563 non-null  int64  \n",
      " 26  source_INTERNET                   993563 non-null  int64  \n",
      " 27  source_TELEAPP                    993563 non-null  int64  \n",
      " 28  device_os_linux                   993563 non-null  int64  \n",
      " 29  device_os_macintosh               993563 non-null  int64  \n",
      " 30  device_os_other                   993563 non-null  int64  \n",
      " 31  device_os_windows                 993563 non-null  int64  \n",
      " 32  device_os_x11                     993563 non-null  int64  \n",
      " 33  intended_balcon_amount_negative   993563 non-null  int64  \n",
      " 34  income                            993563 non-null  float64\n",
      " 35  name_email_similarity             993563 non-null  float64\n",
      " 36  prev_address_months_count         993563 non-null  float64\n",
      " 37  current_address_months_count      993563 non-null  float64\n",
      " 38  customer_age                      993563 non-null  float64\n",
      " 39  days_since_request                993563 non-null  float64\n",
      " 40  intended_balcon_amount            993563 non-null  float64\n",
      " 41  zip_count_4w                      993563 non-null  float64\n",
      " 42  velocity_6h                       993563 non-null  float64\n",
      " 43  velocity_24h                      993563 non-null  float64\n",
      " 44  velocity_4w                       993563 non-null  float64\n",
      " 45  bank_branch_count_8w              993563 non-null  float64\n",
      " 46  date_of_birth_distinct_emails_4w  993563 non-null  float64\n",
      " 47  credit_risk_score                 993563 non-null  float64\n",
      " 48  bank_months_count                 993563 non-null  float64\n",
      " 49  proposed_credit_limit             993563 non-null  float64\n",
      " 50  session_length_in_minutes         993563 non-null  float64\n",
      " 51  device_distinct_emails_8w         993563 non-null  float64\n",
      " 52  month                             993563 non-null  float64\n",
      "dtypes: float64(19), int64(34)\n",
      "memory usage: 401.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Validate data types and non-null values.\n",
    "baf_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud_bool\n",
      "0    982568\n",
      "1     10995\n",
      "Name: count, dtype: int64\n",
      "fraud_bool=1 of all ratio:  0.011\n",
      "fraud_bool=0 of all ratio:  0.989\n"
     ]
    }
   ],
   "source": [
    "# Print target column `fraud_bool` value count\n",
    "print(baf_data['fraud_bool'].value_counts())\n",
    "# Print the pencentage of fraud instances of all records\n",
    "fraud_bool_1 = len(baf_data[baf_data['fraud_bool']==1]) / len(baf_data)\n",
    "fraud_bool_0 = len(baf_data[baf_data['fraud_bool']==0]) / len(baf_data)\n",
    "print(f'fraud_bool=1 of all ratio: {fraud_bool_1: .3f}')\n",
    "print(f'fraud_bool=0 of all ratio: {fraud_bool_0: .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fraud category is quite inbalanced. We need to consider it in later modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Split data into training and testing subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the features will be used for modeling at the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(baf_data.drop(columns='fraud_bool'), baf_data.fraud_bool, test_size=0.3, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((695494, 52), (298069, 52))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((695494,), (298069,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Applying the Machine Learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraud or not is a classification problem. The following supervised learning classification models will be used:\n",
    "\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- K-Nearest Neighbor (KNN)\n",
    "- Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation metrics, F1 score, Recall, Precision, ROC AUC, PR AUC will be calculated and compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to save model name and metrics\n",
    "table = pd.DataFrame(columns=['model_name', 'Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "\n",
    "# Function to calculate metrics and return a dictionary\n",
    "def calculate_metrics(model_name, y_test, y_pred, y_score):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_score)\n",
    "    \n",
    "    # Compute the precision-recall curve\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_score)\n",
    "    pr_auc = auc(recall_curve, precision_curve)\n",
    "    \n",
    "    # Return a dictionary with the results\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'Accuracy_score': accuracy,\n",
    "        'Precision_score': precision,\n",
    "        'Recall_score': recall,\n",
    "        'F1_score': f1,\n",
    "        'roc_auc_score': roc_auc,\n",
    "        'pr_auc': pr_auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the fraud class is quite inbalanced, class_weight='balanced' will be used in Logistic Regression modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\Temp\\ipykernel_5912\\3450119011.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[237180  57620]\n",
      " [   716   2553]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89    294800\n",
      "           1       0.04      0.78      0.08      3269\n",
      "\n",
      "    accuracy                           0.80    298069\n",
      "   macro avg       0.52      0.79      0.49    298069\n",
      "weighted avg       0.99      0.80      0.88    298069\n",
      "\n",
      "                        model_name  Accuracy_score  Precision_score  \\\n",
      "0  Logistic_Regression_C1_balanced        0.804287         0.042428   \n",
      "\n",
      "   Recall_score  F1_score  roc_auc_score    pr_auc  \n",
      "0      0.780973  0.080483        0.87257  0.125287  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Apply logistic regression model to training data\n",
    "logreg = LogisticRegression(penalty='l2', C=1, class_weight='balanced', random_state=47, max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('Logistic_Regression_C1_balanced', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the built in 'balanced' class_weight, Recall score is 0.78, which is fairly good. But Precision is only 0.04, quite low. F1 score is 0.08, pr_auc 0.125. Accuracy score 0.804 and roc_auc score 0.873 high, but doesn't seem to be the best metrics for inbalanced data classification in the current model. Precision and Recall may be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plot_roc_pr_curves function to draw ROC and Precision_Recall curves\n",
    "def plot_roc_pr_curves(model_name, y_test, y_score):\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "\n",
    "    # Compute Precision-Recall curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "\n",
    "    # Create a figure with 2 subplots side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Plot ROC curve on the first subplot\n",
    "    ax1.plot([0, 1], [0, 1], linestyle='--')\n",
    "    ax1.plot(fpr, tpr, marker='.', markersize=1.5, label=model_name)\n",
    "    ax1.set_xlabel('False Positive Rate')\n",
    "    ax1.set_ylabel('True Positive Rate')\n",
    "    ax1.set_title(f'ROC Curve - {model_name}')\n",
    "    ax1.legend()\n",
    "\n",
    "    # Plot Precision-Recall curve on the second subplot\n",
    "    ax2.plot([0, 1], [1, 0], linestyle='--')\n",
    "    ax2.plot(recall, precision, marker='.', markersize=1.5, label=model_name)\n",
    "    ax2.set_xlabel('Recall')\n",
    "    ax2.set_ylabel('Precision')\n",
    "    ax2.set_title(f'Precision-Recall Curve - {model_name}')\n",
    "    ax2.legend()\n",
    "\n",
    "    # Adjust layout and display the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw ROC and Precision-Recall Curves for Logistic Regression\n",
    "plot_roc_pr_curves(\"Logistic Regression\", y_test, y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above two charts, we can see that ROC curve doesn't show the impact of class inbalance. Precision recall curve may be better to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[247194  47606]\n",
      " [   842   2427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91    294800\n",
      "           1       0.05      0.74      0.09      3269\n",
      "\n",
      "    accuracy                           0.84    298069\n",
      "   macro avg       0.52      0.79      0.50    298069\n",
      "weighted avg       0.99      0.84      0.90    298069\n",
      "\n",
      "                        model_name  Accuracy_score  Precision_score  \\\n",
      "0  Logistic_Regression_C1_balanced        0.804287         0.042428   \n",
      "1                    Random Forest        0.837460         0.048508   \n",
      "\n",
      "   Recall_score  F1_score  roc_auc_score    pr_auc  \n",
      "0      0.780973  0.080483       0.872570  0.125287  \n",
      "1      0.742429  0.091066       0.874928  0.128604  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, random_state=47, n_jobs=-1, class_weight='balanced')\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('Random Forest', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw ROC and Precision-Recall Curves for Random Forest\n",
    "plot_roc_pr_curves(\"Random Forest\", y_test, y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.3 Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[293450   1350]\n",
      " [  3072    197]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.13      0.06      0.08      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.56      0.53      0.54    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "                        model_name  Accuracy_score  Precision_score  \\\n",
      "0  Logistic_Regression_C1_balanced        0.804287         0.042428   \n",
      "1                    Random Forest        0.837460         0.048508   \n",
      "2                Gradient Boosting        0.985165         0.127343   \n",
      "\n",
      "   Recall_score  F1_score  roc_auc_score    pr_auc  \n",
      "0      0.780973  0.080483       0.872570  0.125287  \n",
      "1      0.742429  0.091066       0.874928  0.128604  \n",
      "2      0.060263  0.081811       0.876348  0.090367  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(learning_rate=0.1, n_estimators=150, subsample=0.8, max_depth=10, random_state=47)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = gbc.predict(X_test)\n",
    "y_score = gbc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('Gradient Boosting', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw ROC and Precision-Recall Curves for Gradient Boosting\n",
    "plot_roc_pr_curves(\"Gradient Boosting\", y_test, y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.4 K-Nearest neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shenj\\miniconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294800      0]\n",
      " [  3269      0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shenj\\miniconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.00      0.00      0.00      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.49      0.50      0.50    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "                        model_name  Accuracy_score  Precision_score  \\\n",
      "0  Logistic_Regression_C1_balanced        0.804287         0.042428   \n",
      "1                              KNN        0.989033         0.000000   \n",
      "\n",
      "   Recall_score  F1_score  roc_auc_score    pr_auc  \n",
      "0      0.780973  0.080483       0.872570  0.125287  \n",
      "1      0.000000  0.000000       0.770316  0.092424  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shenj\\miniconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\shenj\\miniconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Apply KNN model to the training data\n",
    "# knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2, metric='minkowski', n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2, n_jobs=-1)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "y_score = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('KNN', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems KNN modeling doesn't work well on the current data set. Is it possible for Recall and Precision bother to be 0? Need to discuss with Mentor and try different upsampling or different parameters with KNN and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation train scores: [0.0793177  0.07705479 0.07017544 0.07839795 0.08490963]\n",
      "Mean cross validation train score: 0.07797110221487549\n",
      "Standard deviation of cv train scores: 0.0047275918429300545\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_scores_train= cross_val_score(gbc, X_train, y_train, scoring='f1', cv=5, n_jobs=-1)\n",
    "# cv_scores_test= cross_val_score(gbc, X_test, y_test, scoring='f1', cv=5, n_jobs=-1)\n",
    "print(f'cross validation train scores: {cv_scores_train}')\n",
    "# print(f'cross validation test scores: {cv_scores_test}')\n",
    "cv_scores_rf_train= cv_scores_train.mean()\n",
    "# cv_scores_rf_test= cv_scores_test.mean()\n",
    "cv_scores_rf_train_std= cv_scores_train.std()\n",
    "# cv_scores_std_rf= cv_scores_test.std()\n",
    "print (f'Mean cross validation train score: {cv_scores_rf_train}')\n",
    "print (f'Standard deviation of cv train scores: {cv_scores_rf_train_std}')\n",
    "# print (f'Mean cross validation test score: {cv_scores_rf_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Modeling with resampled training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current results of precision and recall are not great at the same time, which may be related to the inbalance data of the fraud type. Next, we are going to use resampled training data trying to improve the modeling performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 The Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 687768), (1, 687768)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_train_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.1.1 RandomForest Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[265789  29011]\n",
      " [  1287   1982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95    294800\n",
      "           1       0.06      0.61      0.12      3269\n",
      "\n",
      "    accuracy                           0.90    298069\n",
      "   macro avg       0.53      0.75      0.53    298069\n",
      "weighted avg       0.98      0.90      0.94    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0   entropy       0.898352         0.06395     0.606302  0.115697   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.866954  0.112036  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, random_state=47, n_jobs=-1)\n",
    "rfc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('SMOTE_Random Forest', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.1.2 XGboost Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294287    513]\n",
      " [  2996    273]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.35      0.08      0.13      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.67      0.54      0.56    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0       xgb       0.988228        0.347328     0.083512  0.134649   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.878641  0.141921  \n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Apply XGBClassifier to training data\n",
    "xgb = XGBClassifier(objective='binary:logistic', seed=74, eval_metric='aucpr')\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_score = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('SMOTE_xgb', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.1.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[222956  71844]\n",
      " [   945   2324]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.86    294800\n",
      "           1       0.03      0.71      0.06      3269\n",
      "\n",
      "    accuracy                           0.76    298069\n",
      "   macro avg       0.51      0.73      0.46    298069\n",
      "weighted avg       0.99      0.76      0.85    298069\n",
      "\n",
      "   n_neighbors Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0           50       0.755798        0.031334     0.710921  0.060023   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.801767  0.084731  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Apply KNN model to the training data\n",
    "# knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2, metric='minkowski', n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2, n_jobs=-1)\n",
    "knn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "y_score = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('SMOTE_KNN', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.1.4 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[281414  13386]\n",
      " [  1897   1372]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    294800\n",
      "           1       0.09      0.42      0.15      3269\n",
      "\n",
      "    accuracy                           0.95    298069\n",
      "   macro avg       0.54      0.69      0.56    298069\n",
      "weighted avg       0.98      0.95      0.96    298069\n",
      "\n",
      "   C_parameter Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0          0.1       0.948727        0.092967       0.4197  0.152216   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.845516  0.103601  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Apply logistic regression model to training data\n",
    "logreg = LogisticRegression(penalty='l2', C=0.1, solver='lbfgs', random_state=47, max_iter=1000)\n",
    "logreg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('SMOTE_LogisticRegression', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.2 Under-sampling with RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 7726), (1, 7726)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(sorted(Counter(y_train_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.2.1 RandomForest Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[239652  55148]\n",
      " [   747   2522]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.90    294800\n",
      "           1       0.04      0.77      0.08      3269\n",
      "\n",
      "    accuracy                           0.81    298069\n",
      "   macro avg       0.52      0.79      0.49    298069\n",
      "weighted avg       0.99      0.81      0.89    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0   entropy       0.812476        0.043732      0.77149  0.082771   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.873721  0.132063  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, random_state=47, n_jobs=-1)\n",
    "rfc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('RandomUnderSampler_Random Forest', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.2.2 XGboost Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[238011  56789]\n",
      " [   676   2593]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.89    294800\n",
      "           1       0.04      0.79      0.08      3269\n",
      "\n",
      "    accuracy                           0.81    298069\n",
      "   macro avg       0.52      0.80      0.49    298069\n",
      "weighted avg       0.99      0.81      0.88    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0       xgb       0.807209        0.043666     0.793209  0.082776   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.881439  0.135744  \n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Apple XGBClassifier to training data\n",
    "xgb = XGBClassifier(objective='binary:logistic', seed=74, eval_metric='aucpr')\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_score = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('RandomUnderSampler_xgb', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.2.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[217780  77020]\n",
      " [   710   2559]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.74      0.85    294800\n",
      "           1       0.03      0.78      0.06      3269\n",
      "\n",
      "    accuracy                           0.74    298069\n",
      "   macro avg       0.51      0.76      0.46    298069\n",
      "weighted avg       0.99      0.74      0.84    298069\n",
      "\n",
      "   n_neighbors Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0           50       0.739221        0.032157     0.782808  0.061776   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0        0.8365  0.083528  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Apply KNN model to the training data\n",
    "# knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2, metric='minkowski', n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2)\n",
    "knn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "y_score = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('RandomUnderSampler_KNN', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.2.4 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[237651  57149]\n",
      " [   726   2543]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.89    294800\n",
      "           1       0.04      0.78      0.08      3269\n",
      "\n",
      "    accuracy                           0.81    298069\n",
      "   macro avg       0.52      0.79      0.49    298069\n",
      "weighted avg       0.99      0.81      0.88    298069\n",
      "\n",
      "   C_parameter Accuracy_score Precision_score Recall_score F1_score  \\\n",
      "0          0.1       0.805834        0.042602     0.777914  0.08078   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.872246  0.125622  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Apply logistic regression model to training data\n",
    "logreg = LogisticRegression(penalty='l2', C=0.1, solver='lbfgs', random_state=47, max_iter=1000)\n",
    "logreg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('RandomUnderSampler_LogisticRegression', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.3 Under-sampling by removing Tomek’s links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 685578), (1, 7726)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks(n_jobs=-1)\n",
    "X_train_resampled, y_train_resampled = tl.fit_resample(X_train, y_train)\n",
    "\n",
    "print(sorted(Counter(y_train_resampled).items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.3.1 RandomForest Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[246382  48418]\n",
      " [   842   2427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91    294800\n",
      "           1       0.05      0.74      0.09      3269\n",
      "\n",
      "    accuracy                           0.83    298069\n",
      "   macro avg       0.52      0.79      0.50    298069\n",
      "weighted avg       0.99      0.83      0.90    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score F1_score  \\\n",
      "0   entropy       0.834736        0.047733     0.742429   0.0897   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.873076  0.127794  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "# Add class_weight='balanced'\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, class_weight='balanced', random_state=47, n_jobs=-1)\n",
    "rfc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('UnderSamplingRmTomekLinks_Random Forest', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.3.2 XGboost Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294604    196]\n",
      " [  3111    158]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.45      0.05      0.09      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.72      0.52      0.54    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0       xgb       0.988905        0.446328     0.048333  0.087221   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.885752  0.154913  \n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Apply XGBClassifier to training data\n",
    "xgb = XGBClassifier(objective='binary:logistic', seed=74, eval_metric='aucpr')\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_score = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('UnderSamplingRmTomekLinks_xgb', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.3.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294800      0]\n",
      " [  3268      1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       1.00      0.00      0.00      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.99      0.50      0.50    298069\n",
      "weighted avg       0.99      0.99      0.98    298069\n",
      "\n",
      "   n_neighbors Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0           50       0.989036             1.0     0.000306  0.000612   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.771262  0.093185  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Apply KNN model to the training data\n",
    "# knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2, metric='minkowski', n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2)\n",
    "knn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "y_score = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('UnderSamplingRmTomekLinks_KNN', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.3.4 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294772     28]\n",
      " [  3229     40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.59      0.01      0.02      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.79      0.51      0.51    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "   C_parameter Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0          0.1       0.989073        0.588235     0.012236  0.023974   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.871424  0.130207  \n"
     ]
    }
   ],
   "source": [
    "# Apply logistic regression model to training data\n",
    "logreg = LogisticRegression(penalty='l2', C=0.1, solver='lbfgs', random_state=47, max_iter=1000)\n",
    "logreg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('UnderSamplingRmTomekLinks_LogisticRegression', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.4 Under-sampling by EditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 667924), (1, 7726)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "enn = EditedNearestNeighbours(n_neighbors=3, n_jobs=-1)\n",
    "X_train_resampled, y_train_resampled = enn.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_train_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.4.1 RandomForest Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[246942  47858]\n",
      " [   840   2429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91    294800\n",
      "           1       0.05      0.74      0.09      3269\n",
      "\n",
      "    accuracy                           0.84    298069\n",
      "   macro avg       0.52      0.79      0.50    298069\n",
      "weighted avg       0.99      0.84      0.90    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0   entropy       0.836622        0.048303     0.743041  0.090709   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.873774  0.126791  \n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, class_weight='balanced', random_state=47, n_jobs=-1)\n",
    "rfc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('UnderSamplingEditedNearestNeighbours_Random Forest', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.4.2 XGboost Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294387    413]\n",
      " [  2994    275]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.40      0.08      0.14      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.69      0.54      0.57    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0       xgb        0.98857        0.399709     0.084124  0.138994   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.889849  0.160301  \n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Apply xgbClassifier to training data\n",
    "xgb = XGBClassifier(objective='binary:logistic', seed=74, eval_metric='aucpr')\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_score = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('UnderSamplingEditedNearestNeighbours_xgb', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.4.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294793      7]\n",
      " [  3256     13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.65      0.00      0.01      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.82      0.50      0.50    298069\n",
      "weighted avg       0.99      0.99      0.98    298069\n",
      "\n",
      "   n_neighbors Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0           50       0.989053            0.65     0.003977  0.007905   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.774667  0.096543  \n"
     ]
    }
   ],
   "source": [
    "# Apply KNN model to the training data\n",
    "# knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2, metric='minkowski', n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2)\n",
    "knn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "y_score = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('UnderSamplingEditedNearestNeighbours_KNN', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.4.4 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294705     95]\n",
      " [  3184     85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.47      0.03      0.05      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.73      0.51      0.52    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "   C_parameter Accuracy_score Precision_score Recall_score F1_score  \\\n",
      "0          0.1       0.988999        0.472222     0.026002  0.04929   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.871013  0.130367  \n"
     ]
    }
   ],
   "source": [
    "# Apply logistic regression model to training data\n",
    "logreg = LogisticRegression(penalty='l2', C=0.1, solver='lbfgs', random_state=47, max_iter=1000)\n",
    "logreg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('UnderSamplingEditedNearestNeighbours_LogisticRegression', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5 Stacking modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the precision and recall was not very great at the same time still. To improve it, stacking modeling will be tried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294770     30]\n",
      " [  3233     36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.55      0.01      0.02      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.77      0.51      0.51    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as Pipeline_imb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_xgb = Pipeline_imb([\n",
    "    ('rus', RandomUnderSampler(random_state=42)), \n",
    "    ('model_1', XGBClassifier(objective='binary:logistic', seed=74, eval_metric='aucpr', n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipe_knn = Pipeline_imb([\n",
    "    ('enn', EditedNearestNeighbours(n_neighbors=3, n_jobs=-1)), \n",
    "    ('model_2', KNeighborsClassifier(n_neighbors=50, weights='distance', p=2, n_jobs=-1))\n",
    "])\n",
    "\n",
    "level0 = list()\n",
    "level0.append(('xgboost', pipe_xgb))\n",
    "level0.append(('knn', pipe_knn))\n",
    "\n",
    "level1 = LogisticRegression(random_state=74, n_jobs=-1)\n",
    "\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_score = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics and store them in a dictionary\n",
    "metrics = calculate_metrics('stacking modeling 1', y_test, y_pred, y_score)\n",
    "\n",
    "# Append the metrics as a new row to the DataFrame using pd.concat\n",
    "table = pd.concat([table, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      model Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0  stacking       0.989053        0.545455     0.011013  0.021589   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.881819  0.129291  \n"
     ]
    }
   ],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294740     60]\n",
      " [  3207     62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.51      0.02      0.04      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.75      0.51      0.52    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "      model Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0  stacking       0.989039        0.508197     0.018966  0.036567   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.884291  0.144066  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from imblearn.pipeline import Pipeline as Pipeline_imb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_xgb = Pipeline_imb([\n",
    "    ('rus', RandomUnderSampler(random_state=42)), \n",
    "    ('model_1', XGBClassifier(objective='binary:logistic', seed=74, eval_metric='aucpr', n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipe_lgb = Pipeline_imb([\n",
    "    ('tl', TomekLinks(n_jobs=-1)), \n",
    "    ('model_2', LogisticRegression(penalty='l2', C=0.1, solver='lbfgs', random_state=47, max_iter=1000, n_jobs=-1))\n",
    "])\n",
    "\n",
    "level0 = list()\n",
    "level0.append(('xgboost', pipe_xgb))\n",
    "level0.append(('lbg', pipe_lgb))\n",
    "\n",
    "level1 = LogisticRegression(random_state=74, n_jobs=-1)\n",
    "\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_score = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "table = pd.DataFrame(columns = ['model','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['model'] = ['stacking']\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294699    101]\n",
      " [  3144    125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.55      0.04      0.07      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.77      0.52      0.53    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "      model Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0  stacking       0.989113        0.553097     0.038238  0.071531   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.877583  0.153836  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from imblearn.pipeline import Pipeline as Pipeline_imb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_rfc = Pipeline_imb([\n",
    "    ('rus', RandomUnderSampler(random_state=42)), \n",
    "    ('model_1', RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, random_state=47, n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipe_xgb = Pipeline_imb([\n",
    "    ('tl', TomekLinks(n_jobs=-1)), \n",
    "    ('model_2', XGBClassifier(objective='binary:logistic', seed=74, eval_metric='aucpr', n_jobs=-1))\n",
    "])\n",
    "\n",
    "level0 = list()\n",
    "level0.append(('rfc', pipe_rfc))\n",
    "level0.append(('xgb', pipe_xgb))\n",
    "\n",
    "level1 = LogisticRegression(random_state=74, n_jobs=-1)\n",
    "\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_score = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "table = pd.DataFrame(columns = ['model','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['model'] = ['stacking']\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.6 Neural network modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.6.1 Oversample the minority class with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 687768), (1, 687768)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_train_resampled).items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.6.2 Build the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shenj\\miniconda3\\envs\\datascience\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with precision, recall, and AUC metrics\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[Precision(), Recall(), AUC(name='auc')]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Custom Callback for AUC-PR\n",
    "\n",
    "class AUC_PR(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super(AUC_PR, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "        val_targ = self.validation_data[1]\n",
    "        precision, recall, _ = precision_recall_curve(val_targ, val_predict)\n",
    "        auc_pr = auc(recall, precision)\n",
    "        print(f' - val_auc_pr: {auc_pr:.4f}')\n",
    "        logs['val_auc_pr'] = auc_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9920\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 3ms/step - auc: 0.9673 - loss: 0.2146 - precision: 0.9184 - recall: 0.9096 - val_auc: 0.9910 - val_loss: 0.1186 - val_precision: 0.9629 - val_recall: 0.9421 - val_auc_pr: 0.9920\n",
      "Epoch 2/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9926\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3ms/step - auc: 0.9879 - loss: 0.1364 - precision: 0.9570 - recall: 0.9392 - val_auc: 0.9915 - val_loss: 0.1139 - val_precision: 0.9612 - val_recall: 0.9490 - val_auc_pr: 0.9926\n",
      "Epoch 3/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9927\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9886 - loss: 0.1320 - precision: 0.9577 - recall: 0.9420 - val_auc: 0.9917 - val_loss: 0.1127 - val_precision: 0.9625 - val_recall: 0.9487 - val_auc_pr: 0.9927\n",
      "Epoch 4/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9929\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3ms/step - auc: 0.9889 - loss: 0.1305 - precision: 0.9581 - recall: 0.9429 - val_auc: 0.9919 - val_loss: 0.1112 - val_precision: 0.9638 - val_recall: 0.9482 - val_auc_pr: 0.9929\n",
      "Epoch 5/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9929\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9891 - loss: 0.1288 - precision: 0.9578 - recall: 0.9441 - val_auc: 0.9919 - val_loss: 0.1124 - val_precision: 0.9673 - val_recall: 0.9428 - val_auc_pr: 0.9929\n",
      "Epoch 6/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9931\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3ms/step - auc: 0.9892 - loss: 0.1282 - precision: 0.9577 - recall: 0.9449 - val_auc: 0.9922 - val_loss: 0.1099 - val_precision: 0.9597 - val_recall: 0.9547 - val_auc_pr: 0.9931\n",
      "Epoch 7/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9932\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9893 - loss: 0.1276 - precision: 0.9585 - recall: 0.9446 - val_auc: 0.9921 - val_loss: 0.1096 - val_precision: 0.9625 - val_recall: 0.9521 - val_auc_pr: 0.9932\n",
      "Epoch 8/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9932\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 3ms/step - auc: 0.9895 - loss: 0.1271 - precision: 0.9578 - recall: 0.9462 - val_auc: 0.9922 - val_loss: 0.1094 - val_precision: 0.9652 - val_recall: 0.9484 - val_auc_pr: 0.9932\n",
      "Epoch 9/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9932\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - auc: 0.9896 - loss: 0.1257 - precision: 0.9587 - recall: 0.9460 - val_auc: 0.9922 - val_loss: 0.1090 - val_precision: 0.9646 - val_recall: 0.9503 - val_auc_pr: 0.9932\n",
      "Epoch 10/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9897 - loss: 0.1252 - precision: 0.9591 - recall: 0.9469 - val_auc: 0.9925 - val_loss: 0.1085 - val_precision: 0.9674 - val_recall: 0.9489 - val_auc_pr: 0.9934\n",
      "Epoch 11/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9933\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3ms/step - auc: 0.9897 - loss: 0.1256 - precision: 0.9589 - recall: 0.9468 - val_auc: 0.9924 - val_loss: 0.1086 - val_precision: 0.9661 - val_recall: 0.9487 - val_auc_pr: 0.9933\n",
      "Epoch 12/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9933\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9899 - loss: 0.1244 - precision: 0.9592 - recall: 0.9469 - val_auc: 0.9924 - val_loss: 0.1081 - val_precision: 0.9617 - val_recall: 0.9548 - val_auc_pr: 0.9933\n",
      "Epoch 13/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - auc: 0.9899 - loss: 0.1240 - precision: 0.9595 - recall: 0.9479 - val_auc: 0.9925 - val_loss: 0.1079 - val_precision: 0.9668 - val_recall: 0.9488 - val_auc_pr: 0.9934\n",
      "Epoch 14/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - auc: 0.9898 - loss: 0.1245 - precision: 0.9589 - recall: 0.9471 - val_auc: 0.9924 - val_loss: 0.1073 - val_precision: 0.9635 - val_recall: 0.9540 - val_auc_pr: 0.9934\n",
      "Epoch 15/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9897 - loss: 0.1258 - precision: 0.9585 - recall: 0.9467 - val_auc: 0.9925 - val_loss: 0.1069 - val_precision: 0.9638 - val_recall: 0.9537 - val_auc_pr: 0.9934\n",
      "Epoch 16/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3ms/step - auc: 0.9897 - loss: 0.1252 - precision: 0.9593 - recall: 0.9464 - val_auc: 0.9924 - val_loss: 0.1077 - val_precision: 0.9611 - val_recall: 0.9564 - val_auc_pr: 0.9934\n",
      "Epoch 17/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 3ms/step - auc: 0.9899 - loss: 0.1241 - precision: 0.9593 - recall: 0.9479 - val_auc: 0.9924 - val_loss: 0.1072 - val_precision: 0.9626 - val_recall: 0.9551 - val_auc_pr: 0.9934\n",
      "Epoch 18/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3ms/step - auc: 0.9899 - loss: 0.1239 - precision: 0.9597 - recall: 0.9483 - val_auc: 0.9925 - val_loss: 0.1076 - val_precision: 0.9668 - val_recall: 0.9496 - val_auc_pr: 0.9934\n",
      "Epoch 19/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 3ms/step - auc: 0.9899 - loss: 0.1243 - precision: 0.9596 - recall: 0.9477 - val_auc: 0.9924 - val_loss: 0.1068 - val_precision: 0.9634 - val_recall: 0.9557 - val_auc_pr: 0.9935\n",
      "Epoch 20/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9898 - loss: 0.1244 - precision: 0.9592 - recall: 0.9480 - val_auc: 0.9927 - val_loss: 0.1074 - val_precision: 0.9662 - val_recall: 0.9512 - val_auc_pr: 0.9935\n",
      "Epoch 21/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9899 - loss: 0.1235 - precision: 0.9590 - recall: 0.9488 - val_auc: 0.9925 - val_loss: 0.1070 - val_precision: 0.9673 - val_recall: 0.9497 - val_auc_pr: 0.9935\n",
      "Epoch 22/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1236 - precision: 0.9594 - recall: 0.9474 - val_auc: 0.9926 - val_loss: 0.1055 - val_precision: 0.9648 - val_recall: 0.9539 - val_auc_pr: 0.9936\n",
      "Epoch 23/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1234 - precision: 0.9591 - recall: 0.9487 - val_auc: 0.9926 - val_loss: 0.1069 - val_precision: 0.9680 - val_recall: 0.9484 - val_auc_pr: 0.9935\n",
      "Epoch 24/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9899 - loss: 0.1239 - precision: 0.9595 - recall: 0.9481 - val_auc: 0.9926 - val_loss: 0.1067 - val_precision: 0.9674 - val_recall: 0.9496 - val_auc_pr: 0.9935\n",
      "Epoch 25/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1232 - precision: 0.9602 - recall: 0.9483 - val_auc: 0.9927 - val_loss: 0.1056 - val_precision: 0.9658 - val_recall: 0.9526 - val_auc_pr: 0.9936\n",
      "Epoch 26/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3ms/step - auc: 0.9899 - loss: 0.1240 - precision: 0.9591 - recall: 0.9480 - val_auc: 0.9925 - val_loss: 0.1061 - val_precision: 0.9628 - val_recall: 0.9565 - val_auc_pr: 0.9935\n",
      "Epoch 27/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - auc: 0.9899 - loss: 0.1240 - precision: 0.9590 - recall: 0.9485 - val_auc: 0.9925 - val_loss: 0.1068 - val_precision: 0.9657 - val_recall: 0.9512 - val_auc_pr: 0.9935\n",
      "Epoch 28/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9900 - loss: 0.1234 - precision: 0.9595 - recall: 0.9490 - val_auc: 0.9927 - val_loss: 0.1073 - val_precision: 0.9675 - val_recall: 0.9511 - val_auc_pr: 0.9936\n",
      "Epoch 29/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - auc: 0.9899 - loss: 0.1239 - precision: 0.9596 - recall: 0.9489 - val_auc: 0.9927 - val_loss: 0.1060 - val_precision: 0.9668 - val_recall: 0.9515 - val_auc_pr: 0.9936\n",
      "Epoch 30/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9900 - loss: 0.1235 - precision: 0.9592 - recall: 0.9490 - val_auc: 0.9927 - val_loss: 0.1085 - val_precision: 0.9723 - val_recall: 0.9426 - val_auc_pr: 0.9936\n",
      "Epoch 31/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9899 - loss: 0.1240 - precision: 0.9597 - recall: 0.9477 - val_auc: 0.9926 - val_loss: 0.1056 - val_precision: 0.9624 - val_recall: 0.9577 - val_auc_pr: 0.9936\n",
      "Epoch 32/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9901 - loss: 0.1233 - precision: 0.9593 - recall: 0.9487 - val_auc: 0.9927 - val_loss: 0.1050 - val_precision: 0.9635 - val_recall: 0.9561 - val_auc_pr: 0.9936\n",
      "Epoch 33/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1224 - precision: 0.9592 - recall: 0.9498 - val_auc: 0.9927 - val_loss: 0.1063 - val_precision: 0.9640 - val_recall: 0.9556 - val_auc_pr: 0.9936\n",
      "Epoch 34/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1232 - precision: 0.9592 - recall: 0.9486 - val_auc: 0.9927 - val_loss: 0.1056 - val_precision: 0.9666 - val_recall: 0.9524 - val_auc_pr: 0.9936\n",
      "Epoch 35/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1236 - precision: 0.9590 - recall: 0.9486 - val_auc: 0.9926 - val_loss: 0.1054 - val_precision: 0.9641 - val_recall: 0.9551 - val_auc_pr: 0.9936\n",
      "Epoch 36/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1237 - precision: 0.9589 - recall: 0.9485 - val_auc: 0.9927 - val_loss: 0.1067 - val_precision: 0.9650 - val_recall: 0.9536 - val_auc_pr: 0.9936\n",
      "Epoch 37/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1231 - precision: 0.9601 - recall: 0.9481 - val_auc: 0.9925 - val_loss: 0.1062 - val_precision: 0.9658 - val_recall: 0.9530 - val_auc_pr: 0.9936\n",
      "Epoch 38/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1228 - precision: 0.9590 - recall: 0.9486 - val_auc: 0.9926 - val_loss: 0.1056 - val_precision: 0.9638 - val_recall: 0.9564 - val_auc_pr: 0.9936\n",
      "Epoch 39/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1221 - precision: 0.9591 - recall: 0.9497 - val_auc: 0.9927 - val_loss: 0.1058 - val_precision: 0.9664 - val_recall: 0.9522 - val_auc_pr: 0.9936\n",
      "Epoch 40/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1230 - precision: 0.9591 - recall: 0.9493 - val_auc: 0.9926 - val_loss: 0.1053 - val_precision: 0.9623 - val_recall: 0.9583 - val_auc_pr: 0.9936\n",
      "Epoch 41/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1227 - precision: 0.9590 - recall: 0.9497 - val_auc: 0.9926 - val_loss: 0.1058 - val_precision: 0.9634 - val_recall: 0.9559 - val_auc_pr: 0.9936\n",
      "Epoch 42/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1231 - precision: 0.9587 - recall: 0.9494 - val_auc: 0.9927 - val_loss: 0.1049 - val_precision: 0.9654 - val_recall: 0.9548 - val_auc_pr: 0.9937\n",
      "Epoch 43/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1228 - precision: 0.9592 - recall: 0.9490 - val_auc: 0.9926 - val_loss: 0.1058 - val_precision: 0.9675 - val_recall: 0.9514 - val_auc_pr: 0.9936\n",
      "Epoch 44/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1230 - precision: 0.9591 - recall: 0.9485 - val_auc: 0.9926 - val_loss: 0.1058 - val_precision: 0.9640 - val_recall: 0.9551 - val_auc_pr: 0.9936\n",
      "Epoch 45/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1227 - precision: 0.9592 - recall: 0.9494 - val_auc: 0.9926 - val_loss: 0.1076 - val_precision: 0.9702 - val_recall: 0.9463 - val_auc_pr: 0.9936\n",
      "Epoch 46/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1228 - precision: 0.9588 - recall: 0.9490 - val_auc: 0.9927 - val_loss: 0.1052 - val_precision: 0.9651 - val_recall: 0.9546 - val_auc_pr: 0.9936\n",
      "Epoch 47/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1226 - precision: 0.9591 - recall: 0.9498 - val_auc: 0.9927 - val_loss: 0.1060 - val_precision: 0.9677 - val_recall: 0.9503 - val_auc_pr: 0.9936\n",
      "Epoch 48/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1228 - precision: 0.9595 - recall: 0.9492 - val_auc: 0.9927 - val_loss: 0.1052 - val_precision: 0.9662 - val_recall: 0.9528 - val_auc_pr: 0.9936\n",
      "Epoch 49/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9902 - loss: 0.1226 - precision: 0.9591 - recall: 0.9496 - val_auc: 0.9928 - val_loss: 0.1069 - val_precision: 0.9677 - val_recall: 0.9503 - val_auc_pr: 0.9936\n",
      "Epoch 50/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1227 - precision: 0.9589 - recall: 0.9497 - val_auc: 0.9927 - val_loss: 0.1052 - val_precision: 0.9648 - val_recall: 0.9546 - val_auc_pr: 0.9936\n",
      "Epoch 51/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1224 - precision: 0.9593 - recall: 0.9495 - val_auc: 0.9928 - val_loss: 0.1057 - val_precision: 0.9653 - val_recall: 0.9544 - val_auc_pr: 0.9936\n",
      "Epoch 52/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1225 - precision: 0.9586 - recall: 0.9497 - val_auc: 0.9928 - val_loss: 0.1046 - val_precision: 0.9659 - val_recall: 0.9546 - val_auc_pr: 0.9937\n",
      "Epoch 53/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1234 - precision: 0.9588 - recall: 0.9495 - val_auc: 0.9927 - val_loss: 0.1056 - val_precision: 0.9693 - val_recall: 0.9487 - val_auc_pr: 0.9937\n",
      "Epoch 54/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1231 - precision: 0.9594 - recall: 0.9490 - val_auc: 0.9927 - val_loss: 0.1052 - val_precision: 0.9648 - val_recall: 0.9551 - val_auc_pr: 0.9936\n",
      "Epoch 55/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1220 - precision: 0.9591 - recall: 0.9502 - val_auc: 0.9926 - val_loss: 0.1063 - val_precision: 0.9677 - val_recall: 0.9500 - val_auc_pr: 0.9936\n",
      "Epoch 56/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1224 - precision: 0.9586 - recall: 0.9499 - val_auc: 0.9928 - val_loss: 0.1057 - val_precision: 0.9694 - val_recall: 0.9487 - val_auc_pr: 0.9937\n",
      "Epoch 57/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1224 - precision: 0.9592 - recall: 0.9497 - val_auc: 0.9926 - val_loss: 0.1055 - val_precision: 0.9644 - val_recall: 0.9558 - val_auc_pr: 0.9937\n",
      "Epoch 58/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1220 - precision: 0.9588 - recall: 0.9498 - val_auc: 0.9927 - val_loss: 0.1052 - val_precision: 0.9656 - val_recall: 0.9542 - val_auc_pr: 0.9937\n",
      "Epoch 59/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1228 - precision: 0.9595 - recall: 0.9494 - val_auc: 0.9926 - val_loss: 0.1054 - val_precision: 0.9661 - val_recall: 0.9536 - val_auc_pr: 0.9937\n",
      "Epoch 60/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1221 - precision: 0.9593 - recall: 0.9501 - val_auc: 0.9925 - val_loss: 0.1063 - val_precision: 0.9648 - val_recall: 0.9551 - val_auc_pr: 0.9936\n",
      "Epoch 61/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - auc: 0.9903 - loss: 0.1217 - precision: 0.9593 - recall: 0.9503 - val_auc: 0.9928 - val_loss: 0.1064 - val_precision: 0.9681 - val_recall: 0.9500 - val_auc_pr: 0.9936\n",
      "Epoch 62/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - auc: 0.9904 - loss: 0.1210 - precision: 0.9598 - recall: 0.9504 - val_auc: 0.9927 - val_loss: 0.1049 - val_precision: 0.9638 - val_recall: 0.9565 - val_auc_pr: 0.9937\n"
     ]
    }
   ],
   "source": [
    "# Train the Model with the Custom Callback\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_resampled, y_train_resampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define early stopping and custom AUC-PR callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "auc_pr_callback = AUC_PR(validation_data=(X_val_split, y_val_split))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_split, y_train_split,\n",
    "    epochs=100,\n",
    "    batch_size=32,    # limit of memory, also the running speed\n",
    "    validation_data=(X_val_split, y_val_split),\n",
    "    callbacks=[early_stopping, auc_pr_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.6.3 Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9315/9315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - auc: 0.8440 - loss: 0.1173 - precision: 0.1058 - recall: 0.3602\n",
      "loss: 0.11628413200378418\n",
      "compile_metrics: 0.1044442430138588\n",
      "\u001b[1m9315/9315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    294800\n",
      "           1       0.10      0.36      0.16      3269\n",
      "\n",
      "    accuracy                           0.96    298069\n",
      "   macro avg       0.55      0.66      0.57    298069\n",
      "weighted avg       0.98      0.96      0.97    298069\n",
      "\n",
      "[[284785  10015]\n",
      " [  2101   1168]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test data\n",
    "results = model.evaluate(X_test, y_test)\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(f\"{name}: {value}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9593516937353431\n",
      "0.10444424573012609\n",
      "0.3572958091159376\n",
      "0.1616385275394409\n",
      "0.8725704481845618\n",
      "0.12528700350742578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(roc_auc_score(y_test, y_score))\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "print(auc(recall, precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop out test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shenj\\miniconda3\\envs\\datascience\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9928\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 3ms/step - auc: 0.9774 - loss: 0.1793 - precision: 0.9339 - recall: 0.9207 - val_auc: 0.9918 - val_loss: 0.1123 - val_precision: 0.9570 - val_recall: 0.9549 - val_auc_pr: 0.9928\n",
      "Epoch 2/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9932\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9903 - loss: 0.1220 - precision: 0.9574 - recall: 0.9487 - val_auc: 0.9924 - val_loss: 0.1089 - val_precision: 0.9552 - val_recall: 0.9609 - val_auc_pr: 0.9932\n",
      "Epoch 3/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - auc: 0.9909 - loss: 0.1181 - precision: 0.9586 - recall: 0.9511 - val_auc: 0.9927 - val_loss: 0.1058 - val_precision: 0.9576 - val_recall: 0.9607 - val_auc_pr: 0.9935\n",
      "Epoch 4/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9938\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 4ms/step - auc: 0.9912 - loss: 0.1159 - precision: 0.9587 - recall: 0.9533 - val_auc: 0.9930 - val_loss: 0.1042 - val_precision: 0.9602 - val_recall: 0.9599 - val_auc_pr: 0.9938\n",
      "Epoch 5/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 4ms/step - auc: 0.9913 - loss: 0.1148 - precision: 0.9591 - recall: 0.9536 - val_auc: 0.9931 - val_loss: 0.1026 - val_precision: 0.9630 - val_recall: 0.9587 - val_auc_pr: 0.9939\n",
      "Epoch 6/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 4ms/step - auc: 0.9915 - loss: 0.1142 - precision: 0.9591 - recall: 0.9541 - val_auc: 0.9932 - val_loss: 0.1024 - val_precision: 0.9607 - val_recall: 0.9607 - val_auc_pr: 0.9939\n",
      "Epoch 7/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 4ms/step - auc: 0.9915 - loss: 0.1134 - precision: 0.9599 - recall: 0.9538 - val_auc: 0.9932 - val_loss: 0.1026 - val_precision: 0.9648 - val_recall: 0.9575 - val_auc_pr: 0.9940\n",
      "Epoch 8/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 4ms/step - auc: 0.9916 - loss: 0.1128 - precision: 0.9598 - recall: 0.9557 - val_auc: 0.9934 - val_loss: 0.1007 - val_precision: 0.9618 - val_recall: 0.9612 - val_auc_pr: 0.9941\n",
      "Epoch 9/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 5ms/step - auc: 0.9917 - loss: 0.1123 - precision: 0.9597 - recall: 0.9561 - val_auc: 0.9933 - val_loss: 0.1006 - val_precision: 0.9640 - val_recall: 0.9593 - val_auc_pr: 0.9941\n",
      "Epoch 10/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 4ms/step - auc: 0.9918 - loss: 0.1111 - precision: 0.9604 - recall: 0.9563 - val_auc: 0.9935 - val_loss: 0.0996 - val_precision: 0.9633 - val_recall: 0.9606 - val_auc_pr: 0.9942\n",
      "Epoch 11/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 4ms/step - auc: 0.9918 - loss: 0.1108 - precision: 0.9604 - recall: 0.9563 - val_auc: 0.9934 - val_loss: 0.1001 - val_precision: 0.9605 - val_recall: 0.9635 - val_auc_pr: 0.9942\n",
      "Epoch 12/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9943\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 4ms/step - auc: 0.9918 - loss: 0.1110 - precision: 0.9602 - recall: 0.9564 - val_auc: 0.9935 - val_loss: 0.0991 - val_precision: 0.9613 - val_recall: 0.9637 - val_auc_pr: 0.9943\n",
      "Epoch 13/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 4ms/step - auc: 0.9917 - loss: 0.1115 - precision: 0.9603 - recall: 0.9564 - val_auc: 0.9935 - val_loss: 0.0997 - val_precision: 0.9623 - val_recall: 0.9622 - val_auc_pr: 0.9942\n",
      "Epoch 14/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 4ms/step - auc: 0.9920 - loss: 0.1098 - precision: 0.9610 - recall: 0.9568 - val_auc: 0.9934 - val_loss: 0.1003 - val_precision: 0.9589 - val_recall: 0.9647 - val_auc_pr: 0.9942\n",
      "Epoch 15/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9943\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 4ms/step - auc: 0.9921 - loss: 0.1090 - precision: 0.9607 - recall: 0.9576 - val_auc: 0.9935 - val_loss: 0.0990 - val_precision: 0.9643 - val_recall: 0.9613 - val_auc_pr: 0.9943\n",
      "Epoch 16/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9943\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 4ms/step - auc: 0.9920 - loss: 0.1095 - precision: 0.9611 - recall: 0.9573 - val_auc: 0.9935 - val_loss: 0.0989 - val_precision: 0.9638 - val_recall: 0.9619 - val_auc_pr: 0.9943\n",
      "Epoch 17/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9943\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 4ms/step - auc: 0.9921 - loss: 0.1088 - precision: 0.9611 - recall: 0.9578 - val_auc: 0.9934 - val_loss: 0.0989 - val_precision: 0.9641 - val_recall: 0.9612 - val_auc_pr: 0.9943\n",
      "Epoch 18/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3ms/step - auc: 0.9920 - loss: 0.1100 - precision: 0.9610 - recall: 0.9569 - val_auc: 0.9937 - val_loss: 0.0980 - val_precision: 0.9622 - val_recall: 0.9643 - val_auc_pr: 0.9944\n",
      "Epoch 19/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 3ms/step - auc: 0.9920 - loss: 0.1093 - precision: 0.9612 - recall: 0.9571 - val_auc: 0.9937 - val_loss: 0.0985 - val_precision: 0.9628 - val_recall: 0.9632 - val_auc_pr: 0.9944\n",
      "Epoch 20/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1090 - precision: 0.9611 - recall: 0.9573 - val_auc: 0.9937 - val_loss: 0.0987 - val_precision: 0.9654 - val_recall: 0.9599 - val_auc_pr: 0.9944\n",
      "Epoch 21/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 3ms/step - auc: 0.9920 - loss: 0.1094 - precision: 0.9611 - recall: 0.9570 - val_auc: 0.9937 - val_loss: 0.0977 - val_precision: 0.9622 - val_recall: 0.9642 - val_auc_pr: 0.9944\n",
      "Epoch 22/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3ms/step - auc: 0.9920 - loss: 0.1096 - precision: 0.9606 - recall: 0.9573 - val_auc: 0.9937 - val_loss: 0.0981 - val_precision: 0.9636 - val_recall: 0.9632 - val_auc_pr: 0.9944\n",
      "Epoch 23/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1091 - precision: 0.9604 - recall: 0.9580 - val_auc: 0.9937 - val_loss: 0.0974 - val_precision: 0.9629 - val_recall: 0.9646 - val_auc_pr: 0.9944\n",
      "Epoch 24/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 3ms/step - auc: 0.9920 - loss: 0.1094 - precision: 0.9609 - recall: 0.9575 - val_auc: 0.9936 - val_loss: 0.0977 - val_precision: 0.9616 - val_recall: 0.9653 - val_auc_pr: 0.9944\n",
      "Epoch 25/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1082 - precision: 0.9613 - recall: 0.9584 - val_auc: 0.9937 - val_loss: 0.0982 - val_precision: 0.9654 - val_recall: 0.9608 - val_auc_pr: 0.9944\n",
      "Epoch 26/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1087 - precision: 0.9609 - recall: 0.9583 - val_auc: 0.9937 - val_loss: 0.0977 - val_precision: 0.9633 - val_recall: 0.9633 - val_auc_pr: 0.9944\n",
      "Epoch 27/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 3ms/step - auc: 0.9920 - loss: 0.1096 - precision: 0.9608 - recall: 0.9578 - val_auc: 0.9937 - val_loss: 0.0975 - val_precision: 0.9645 - val_recall: 0.9625 - val_auc_pr: 0.9944\n",
      "Epoch 28/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1082 - precision: 0.9615 - recall: 0.9582 - val_auc: 0.9938 - val_loss: 0.0973 - val_precision: 0.9631 - val_recall: 0.9643 - val_auc_pr: 0.9945\n",
      "Epoch 29/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - auc: 0.9923 - loss: 0.1075 - precision: 0.9614 - recall: 0.9581 - val_auc: 0.9937 - val_loss: 0.0971 - val_precision: 0.9633 - val_recall: 0.9634 - val_auc_pr: 0.9945\n",
      "Epoch 30/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1085 - precision: 0.9610 - recall: 0.9581 - val_auc: 0.9938 - val_loss: 0.0967 - val_precision: 0.9623 - val_recall: 0.9655 - val_auc_pr: 0.9945\n",
      "Epoch 31/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1085 - precision: 0.9616 - recall: 0.9580 - val_auc: 0.9938 - val_loss: 0.0978 - val_precision: 0.9638 - val_recall: 0.9634 - val_auc_pr: 0.9945\n",
      "Epoch 32/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1078 - precision: 0.9618 - recall: 0.9586 - val_auc: 0.9938 - val_loss: 0.0971 - val_precision: 0.9662 - val_recall: 0.9608 - val_auc_pr: 0.9945\n",
      "Epoch 33/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1084 - precision: 0.9614 - recall: 0.9584 - val_auc: 0.9938 - val_loss: 0.0970 - val_precision: 0.9636 - val_recall: 0.9634 - val_auc_pr: 0.9945\n",
      "Epoch 34/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1084 - precision: 0.9616 - recall: 0.9583 - val_auc: 0.9938 - val_loss: 0.0985 - val_precision: 0.9619 - val_recall: 0.9660 - val_auc_pr: 0.9945\n",
      "Epoch 35/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1081 - precision: 0.9615 - recall: 0.9585 - val_auc: 0.9938 - val_loss: 0.0974 - val_precision: 0.9614 - val_recall: 0.9662 - val_auc_pr: 0.9945\n",
      "Epoch 36/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9923 - loss: 0.1077 - precision: 0.9612 - recall: 0.9585 - val_auc: 0.9938 - val_loss: 0.0969 - val_precision: 0.9627 - val_recall: 0.9649 - val_auc_pr: 0.9945\n",
      "Epoch 37/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9923 - loss: 0.1075 - precision: 0.9618 - recall: 0.9583 - val_auc: 0.9938 - val_loss: 0.0971 - val_precision: 0.9654 - val_recall: 0.9619 - val_auc_pr: 0.9945\n",
      "Epoch 38/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1079 - precision: 0.9615 - recall: 0.9585 - val_auc: 0.9937 - val_loss: 0.0967 - val_precision: 0.9643 - val_recall: 0.9625 - val_auc_pr: 0.9945\n",
      "Epoch 39/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1081 - precision: 0.9616 - recall: 0.9585 - val_auc: 0.9937 - val_loss: 0.0961 - val_precision: 0.9642 - val_recall: 0.9647 - val_auc_pr: 0.9945\n",
      "Epoch 40/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 3ms/step - auc: 0.9923 - loss: 0.1075 - precision: 0.9616 - recall: 0.9586 - val_auc: 0.9938 - val_loss: 0.0976 - val_precision: 0.9667 - val_recall: 0.9599 - val_auc_pr: 0.9945\n",
      "Epoch 41/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1081 - precision: 0.9614 - recall: 0.9584 - val_auc: 0.9939 - val_loss: 0.0980 - val_precision: 0.9667 - val_recall: 0.9603 - val_auc_pr: 0.9945\n",
      "Epoch 42/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 3ms/step - auc: 0.9923 - loss: 0.1075 - precision: 0.9619 - recall: 0.9583 - val_auc: 0.9938 - val_loss: 0.0985 - val_precision: 0.9690 - val_recall: 0.9576 - val_auc_pr: 0.9945\n",
      "Epoch 43/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1079 - precision: 0.9616 - recall: 0.9580 - val_auc: 0.9938 - val_loss: 0.0965 - val_precision: 0.9631 - val_recall: 0.9645 - val_auc_pr: 0.9945\n",
      "Epoch 44/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9946\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 3ms/step - auc: 0.9923 - loss: 0.1073 - precision: 0.9619 - recall: 0.9589 - val_auc: 0.9939 - val_loss: 0.0976 - val_precision: 0.9680 - val_recall: 0.9593 - val_auc_pr: 0.9946\n",
      "Epoch 45/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1084 - precision: 0.9613 - recall: 0.9580 - val_auc: 0.9938 - val_loss: 0.0968 - val_precision: 0.9633 - val_recall: 0.9644 - val_auc_pr: 0.9945\n",
      "Epoch 46/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3ms/step - auc: 0.9923 - loss: 0.1074 - precision: 0.9610 - recall: 0.9587 - val_auc: 0.9938 - val_loss: 0.0967 - val_precision: 0.9629 - val_recall: 0.9650 - val_auc_pr: 0.9945\n",
      "Epoch 47/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2ms/step - auc: 0.9923 - loss: 0.1069 - precision: 0.9624 - recall: 0.9587 - val_auc: 0.9938 - val_loss: 0.0969 - val_precision: 0.9630 - val_recall: 0.9648 - val_auc_pr: 0.9945\n",
      "Epoch 48/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2ms/step - auc: 0.9924 - loss: 0.1067 - precision: 0.9619 - recall: 0.9587 - val_auc: 0.9939 - val_loss: 0.0965 - val_precision: 0.9657 - val_recall: 0.9618 - val_auc_pr: 0.9945\n",
      "Epoch 49/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2ms/step - auc: 0.9923 - loss: 0.1074 - precision: 0.9617 - recall: 0.9589 - val_auc: 0.9939 - val_loss: 0.0978 - val_precision: 0.9602 - val_recall: 0.9680 - val_auc_pr: 0.9945\n",
      "\u001b[1m9315/9315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - auc: 0.8347 - loss: 0.1176 - precision: 0.1054 - recall: 0.3772\n",
      "loss: 0.11640780419111252\n",
      "compile_metrics: 0.10289252549409866\n",
      "\u001b[1m9315/9315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    294800\n",
      "           1       0.10      0.37      0.16      3269\n",
      "\n",
      "    accuracy                           0.96    298069\n",
      "   macro avg       0.55      0.67      0.57    298069\n",
      "weighted avg       0.98      0.96      0.97    298069\n",
      "\n",
      "[[284224  10576]\n",
      " [  2056   1213]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with precision, recall, and AUC metrics\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[Precision(), Recall(), AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Create a Custom Callback for AUC-PR\n",
    "\n",
    "class AUC_PR(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super(AUC_PR, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "        val_targ = self.validation_data[1]\n",
    "        precision, recall, _ = precision_recall_curve(val_targ, val_predict)\n",
    "        auc_pr = auc(recall, precision)\n",
    "        print(f' - val_auc_pr: {auc_pr:.4f}')\n",
    "        logs['val_auc_pr'] = auc_pr\n",
    "\n",
    "# Train the Model with the Custom Callback\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_resampled, y_train_resampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define early stopping and custom AUC-PR callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "auc_pr_callback = AUC_PR(validation_data=(X_val_split, y_val_split))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_split, y_train_split,\n",
    "    epochs=100,\n",
    "    batch_size=32,    # limit of memory, also the running speed\n",
    "    validation_data=(X_val_split, y_val_split),\n",
    "    callbacks=[early_stopping, auc_pr_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on the test data\n",
    "results = model.evaluate(X_test, y_test)\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(f\"{name}: {value}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    294800\n",
      "           1       0.10      0.37      0.16      3269\n",
      "\n",
      "    accuracy                           0.96    298069\n",
      "   macro avg       0.55      0.67      0.57    298069\n",
      "weighted avg       0.98      0.96      0.97    298069\n",
      "\n",
      "[[284224  10576]\n",
      " [  2056   1213]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 687768), (1, 687768)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shenj\\miniconda3\\envs\\datascience\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9926\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3ms/step - auc: 0.9740 - loss: 0.1939 - precision: 0.9260 - recall: 0.9196 - val_auc: 0.9916 - val_loss: 0.1146 - val_precision: 0.9611 - val_recall: 0.9473 - val_auc_pr: 0.9926\n",
      "Epoch 2/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9929\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - auc: 0.9873 - loss: 0.1396 - precision: 0.9506 - recall: 0.9443 - val_auc: 0.9921 - val_loss: 0.1121 - val_precision: 0.9545 - val_recall: 0.9574 - val_auc_pr: 0.9929\n",
      "Epoch 3/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9931\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3ms/step - auc: 0.9890 - loss: 0.1307 - precision: 0.9539 - recall: 0.9467 - val_auc: 0.9923 - val_loss: 0.1102 - val_precision: 0.9649 - val_recall: 0.9458 - val_auc_pr: 0.9931\n",
      "Epoch 4/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9933\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3ms/step - auc: 0.9893 - loss: 0.1285 - precision: 0.9551 - recall: 0.9477 - val_auc: 0.9925 - val_loss: 0.1087 - val_precision: 0.9528 - val_recall: 0.9617 - val_auc_pr: 0.9933\n",
      "Epoch 5/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9933\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - auc: 0.9898 - loss: 0.1253 - precision: 0.9555 - recall: 0.9492 - val_auc: 0.9925 - val_loss: 0.1079 - val_precision: 0.9594 - val_recall: 0.9552 - val_auc_pr: 0.9933\n",
      "Epoch 6/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3ms/step - auc: 0.9898 - loss: 0.1252 - precision: 0.9555 - recall: 0.9487 - val_auc: 0.9927 - val_loss: 0.1074 - val_precision: 0.9571 - val_recall: 0.9588 - val_auc_pr: 0.9934\n",
      "Epoch 7/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1232 - precision: 0.9564 - recall: 0.9496 - val_auc: 0.9929 - val_loss: 0.1057 - val_precision: 0.9585 - val_recall: 0.9584 - val_auc_pr: 0.9936\n",
      "Epoch 8/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 3ms/step - auc: 0.9904 - loss: 0.1209 - precision: 0.9569 - recall: 0.9511 - val_auc: 0.9930 - val_loss: 0.1051 - val_precision: 0.9587 - val_recall: 0.9588 - val_auc_pr: 0.9937\n",
      "Epoch 9/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3ms/step - auc: 0.9904 - loss: 0.1214 - precision: 0.9564 - recall: 0.9505 - val_auc: 0.9929 - val_loss: 0.1060 - val_precision: 0.9581 - val_recall: 0.9596 - val_auc_pr: 0.9936\n",
      "Epoch 10/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 3ms/step - auc: 0.9904 - loss: 0.1212 - precision: 0.9565 - recall: 0.9513 - val_auc: 0.9930 - val_loss: 0.1061 - val_precision: 0.9547 - val_recall: 0.9635 - val_auc_pr: 0.9937\n",
      "Epoch 11/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3ms/step - auc: 0.9905 - loss: 0.1204 - precision: 0.9575 - recall: 0.9512 - val_auc: 0.9930 - val_loss: 0.1045 - val_precision: 0.9580 - val_recall: 0.9602 - val_auc_pr: 0.9937\n",
      "Epoch 12/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9938\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - auc: 0.9905 - loss: 0.1204 - precision: 0.9568 - recall: 0.9516 - val_auc: 0.9931 - val_loss: 0.1040 - val_precision: 0.9572 - val_recall: 0.9621 - val_auc_pr: 0.9938\n",
      "Epoch 13/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3ms/step - auc: 0.9905 - loss: 0.1204 - precision: 0.9568 - recall: 0.9512 - val_auc: 0.9931 - val_loss: 0.1044 - val_precision: 0.9606 - val_recall: 0.9582 - val_auc_pr: 0.9937\n",
      "Epoch 14/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9938\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 3ms/step - auc: 0.9906 - loss: 0.1195 - precision: 0.9571 - recall: 0.9517 - val_auc: 0.9931 - val_loss: 0.1036 - val_precision: 0.9588 - val_recall: 0.9608 - val_auc_pr: 0.9938\n",
      "Epoch 15/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9938\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3ms/step - auc: 0.9906 - loss: 0.1197 - precision: 0.9571 - recall: 0.9522 - val_auc: 0.9932 - val_loss: 0.1036 - val_precision: 0.9609 - val_recall: 0.9589 - val_auc_pr: 0.9938\n",
      "Epoch 16/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - auc: 0.9907 - loss: 0.1190 - precision: 0.9573 - recall: 0.9519 - val_auc: 0.9932 - val_loss: 0.1027 - val_precision: 0.9616 - val_recall: 0.9585 - val_auc_pr: 0.9939\n",
      "Epoch 17/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3ms/step - auc: 0.9908 - loss: 0.1189 - precision: 0.9573 - recall: 0.9520 - val_auc: 0.9932 - val_loss: 0.1032 - val_precision: 0.9611 - val_recall: 0.9591 - val_auc_pr: 0.9939\n",
      "Epoch 18/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - auc: 0.9907 - loss: 0.1193 - precision: 0.9571 - recall: 0.9520 - val_auc: 0.9932 - val_loss: 0.1035 - val_precision: 0.9552 - val_recall: 0.9639 - val_auc_pr: 0.9939\n",
      "Epoch 19/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3ms/step - auc: 0.9908 - loss: 0.1187 - precision: 0.9566 - recall: 0.9523 - val_auc: 0.9933 - val_loss: 0.1027 - val_precision: 0.9579 - val_recall: 0.9628 - val_auc_pr: 0.9939\n",
      "Epoch 20/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3ms/step - auc: 0.9908 - loss: 0.1182 - precision: 0.9577 - recall: 0.9523 - val_auc: 0.9932 - val_loss: 0.1030 - val_precision: 0.9578 - val_recall: 0.9622 - val_auc_pr: 0.9939\n",
      "Epoch 21/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3ms/step - auc: 0.9910 - loss: 0.1173 - precision: 0.9576 - recall: 0.9525 - val_auc: 0.9933 - val_loss: 0.1033 - val_precision: 0.9630 - val_recall: 0.9577 - val_auc_pr: 0.9940\n",
      "Epoch 22/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - auc: 0.9909 - loss: 0.1180 - precision: 0.9572 - recall: 0.9522 - val_auc: 0.9933 - val_loss: 0.1035 - val_precision: 0.9537 - val_recall: 0.9664 - val_auc_pr: 0.9940\n",
      "Epoch 23/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - auc: 0.9908 - loss: 0.1182 - precision: 0.9575 - recall: 0.9520 - val_auc: 0.9933 - val_loss: 0.1027 - val_precision: 0.9583 - val_recall: 0.9626 - val_auc_pr: 0.9939\n",
      "Epoch 24/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - auc: 0.9910 - loss: 0.1175 - precision: 0.9578 - recall: 0.9532 - val_auc: 0.9933 - val_loss: 0.1042 - val_precision: 0.9588 - val_recall: 0.9613 - val_auc_pr: 0.9939\n",
      "Epoch 25/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9909 - loss: 0.1177 - precision: 0.9573 - recall: 0.9532 - val_auc: 0.9933 - val_loss: 0.1025 - val_precision: 0.9634 - val_recall: 0.9571 - val_auc_pr: 0.9940\n",
      "Epoch 26/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - auc: 0.9910 - loss: 0.1171 - precision: 0.9581 - recall: 0.9530 - val_auc: 0.9934 - val_loss: 0.1017 - val_precision: 0.9577 - val_recall: 0.9640 - val_auc_pr: 0.9940\n",
      "Epoch 27/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9910 - loss: 0.1175 - precision: 0.9575 - recall: 0.9528 - val_auc: 0.9934 - val_loss: 0.1016 - val_precision: 0.9612 - val_recall: 0.9597 - val_auc_pr: 0.9940\n",
      "Epoch 28/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1166 - precision: 0.9578 - recall: 0.9535 - val_auc: 0.9933 - val_loss: 0.1016 - val_precision: 0.9614 - val_recall: 0.9599 - val_auc_pr: 0.9940\n",
      "Epoch 29/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - auc: 0.9911 - loss: 0.1165 - precision: 0.9579 - recall: 0.9535 - val_auc: 0.9934 - val_loss: 0.1015 - val_precision: 0.9580 - val_recall: 0.9631 - val_auc_pr: 0.9940\n",
      "Epoch 30/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1169 - precision: 0.9580 - recall: 0.9534 - val_auc: 0.9934 - val_loss: 0.1023 - val_precision: 0.9666 - val_recall: 0.9535 - val_auc_pr: 0.9940\n",
      "Epoch 31/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9910 - loss: 0.1165 - precision: 0.9584 - recall: 0.9533 - val_auc: 0.9934 - val_loss: 0.1009 - val_precision: 0.9622 - val_recall: 0.9591 - val_auc_pr: 0.9941\n",
      "Epoch 32/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9910 - loss: 0.1171 - precision: 0.9576 - recall: 0.9530 - val_auc: 0.9934 - val_loss: 0.1033 - val_precision: 0.9569 - val_recall: 0.9645 - val_auc_pr: 0.9940\n",
      "Epoch 33/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - auc: 0.9910 - loss: 0.1164 - precision: 0.9579 - recall: 0.9538 - val_auc: 0.9935 - val_loss: 0.1007 - val_precision: 0.9604 - val_recall: 0.9616 - val_auc_pr: 0.9941\n",
      "Epoch 34/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1164 - precision: 0.9581 - recall: 0.9533 - val_auc: 0.9935 - val_loss: 0.1005 - val_precision: 0.9594 - val_recall: 0.9629 - val_auc_pr: 0.9941\n",
      "Epoch 35/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1165 - precision: 0.9577 - recall: 0.9538 - val_auc: 0.9934 - val_loss: 0.1017 - val_precision: 0.9581 - val_recall: 0.9624 - val_auc_pr: 0.9940\n",
      "Epoch 36/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1158 - precision: 0.9577 - recall: 0.9537 - val_auc: 0.9935 - val_loss: 0.1006 - val_precision: 0.9586 - val_recall: 0.9634 - val_auc_pr: 0.9941\n",
      "Epoch 37/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1166 - precision: 0.9577 - recall: 0.9537 - val_auc: 0.9935 - val_loss: 0.1006 - val_precision: 0.9581 - val_recall: 0.9642 - val_auc_pr: 0.9941\n",
      "Epoch 38/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9910 - loss: 0.1169 - precision: 0.9576 - recall: 0.9530 - val_auc: 0.9935 - val_loss: 0.1005 - val_precision: 0.9602 - val_recall: 0.9622 - val_auc_pr: 0.9941\n",
      "Epoch 39/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1166 - precision: 0.9582 - recall: 0.9528 - val_auc: 0.9935 - val_loss: 0.1009 - val_precision: 0.9596 - val_recall: 0.9626 - val_auc_pr: 0.9941\n",
      "Epoch 40/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1157 - precision: 0.9585 - recall: 0.9534 - val_auc: 0.9935 - val_loss: 0.1013 - val_precision: 0.9606 - val_recall: 0.9614 - val_auc_pr: 0.9941\n",
      "Epoch 41/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1160 - precision: 0.9578 - recall: 0.9536 - val_auc: 0.9934 - val_loss: 0.1007 - val_precision: 0.9599 - val_recall: 0.9626 - val_auc_pr: 0.9941\n",
      "Epoch 42/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - auc: 0.9912 - loss: 0.1160 - precision: 0.9577 - recall: 0.9536 - val_auc: 0.9935 - val_loss: 0.1006 - val_precision: 0.9594 - val_recall: 0.9634 - val_auc_pr: 0.9941\n",
      "Epoch 43/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1156 - precision: 0.9585 - recall: 0.9538 - val_auc: 0.9935 - val_loss: 0.1005 - val_precision: 0.9609 - val_recall: 0.9607 - val_auc_pr: 0.9941\n",
      "Epoch 44/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1166 - precision: 0.9574 - recall: 0.9537 - val_auc: 0.9935 - val_loss: 0.1003 - val_precision: 0.9605 - val_recall: 0.9623 - val_auc_pr: 0.9941\n",
      "Epoch 45/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1154 - precision: 0.9583 - recall: 0.9539 - val_auc: 0.9936 - val_loss: 0.1004 - val_precision: 0.9617 - val_recall: 0.9613 - val_auc_pr: 0.9942\n",
      "Epoch 46/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1160 - precision: 0.9582 - recall: 0.9539 - val_auc: 0.9936 - val_loss: 0.1008 - val_precision: 0.9591 - val_recall: 0.9635 - val_auc_pr: 0.9942\n",
      "Epoch 47/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1156 - precision: 0.9579 - recall: 0.9541 - val_auc: 0.9936 - val_loss: 0.1006 - val_precision: 0.9596 - val_recall: 0.9634 - val_auc_pr: 0.9942\n",
      "Epoch 48/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9913 - loss: 0.1154 - precision: 0.9579 - recall: 0.9540 - val_auc: 0.9936 - val_loss: 0.1004 - val_precision: 0.9598 - val_recall: 0.9636 - val_auc_pr: 0.9942\n",
      "Epoch 49/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9913 - loss: 0.1149 - precision: 0.9583 - recall: 0.9535 - val_auc: 0.9936 - val_loss: 0.1008 - val_precision: 0.9629 - val_recall: 0.9595 - val_auc_pr: 0.9942\n",
      "Epoch 50/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9913 - loss: 0.1152 - precision: 0.9578 - recall: 0.9541 - val_auc: 0.9935 - val_loss: 0.1007 - val_precision: 0.9574 - val_recall: 0.9651 - val_auc_pr: 0.9941\n",
      "Epoch 51/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - auc: 0.9913 - loss: 0.1148 - precision: 0.9580 - recall: 0.9547 - val_auc: 0.9936 - val_loss: 0.0993 - val_precision: 0.9616 - val_recall: 0.9619 - val_auc_pr: 0.9942\n",
      "Epoch 52/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - auc: 0.9911 - loss: 0.1161 - precision: 0.9579 - recall: 0.9536 - val_auc: 0.9935 - val_loss: 0.1005 - val_precision: 0.9611 - val_recall: 0.9613 - val_auc_pr: 0.9942\n",
      "Epoch 53/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1158 - precision: 0.9581 - recall: 0.9537 - val_auc: 0.9935 - val_loss: 0.1004 - val_precision: 0.9600 - val_recall: 0.9628 - val_auc_pr: 0.9942\n",
      "Epoch 54/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9913 - loss: 0.1153 - precision: 0.9579 - recall: 0.9542 - val_auc: 0.9935 - val_loss: 0.1002 - val_precision: 0.9603 - val_recall: 0.9628 - val_auc_pr: 0.9942\n",
      "Epoch 55/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9913 - loss: 0.1154 - precision: 0.9578 - recall: 0.9545 - val_auc: 0.9936 - val_loss: 0.1001 - val_precision: 0.9656 - val_recall: 0.9564 - val_auc_pr: 0.9942\n",
      "Epoch 56/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1156 - precision: 0.9582 - recall: 0.9540 - val_auc: 0.9936 - val_loss: 0.0997 - val_precision: 0.9624 - val_recall: 0.9604 - val_auc_pr: 0.9942\n",
      "Epoch 57/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9913 - loss: 0.1149 - precision: 0.9583 - recall: 0.9546 - val_auc: 0.9936 - val_loss: 0.0996 - val_precision: 0.9625 - val_recall: 0.9609 - val_auc_pr: 0.9942\n",
      "Epoch 58/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - auc: 0.9913 - loss: 0.1152 - precision: 0.9584 - recall: 0.9543 - val_auc: 0.9936 - val_loss: 0.0994 - val_precision: 0.9612 - val_recall: 0.9623 - val_auc_pr: 0.9942\n",
      "Epoch 59/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - auc: 0.9913 - loss: 0.1152 - precision: 0.9583 - recall: 0.9544 - val_auc: 0.9936 - val_loss: 0.0995 - val_precision: 0.9638 - val_recall: 0.9597 - val_auc_pr: 0.9942\n",
      "Epoch 60/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - auc: 0.9913 - loss: 0.1147 - precision: 0.9587 - recall: 0.9543 - val_auc: 0.9935 - val_loss: 0.0999 - val_precision: 0.9646 - val_recall: 0.9586 - val_auc_pr: 0.9942\n",
      "Epoch 61/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - auc: 0.9914 - loss: 0.1146 - precision: 0.9583 - recall: 0.9547 - val_auc: 0.9936 - val_loss: 0.0996 - val_precision: 0.9608 - val_recall: 0.9625 - val_auc_pr: 0.9942\n",
      "\u001b[1m9315/9315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - auc: 0.8427 - loss: 0.1168 - precision: 0.0997 - recall: 0.3789\n",
      "loss: 0.11602653563022614\n",
      "compile_metrics: 0.09824926406145096\n",
      "\u001b[1m9315/9315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    294800\n",
      "           1       0.10      0.38      0.16      3269\n",
      "\n",
      "    accuracy                           0.96    298069\n",
      "   macro avg       0.55      0.67      0.57    298069\n",
      "weighted avg       0.98      0.96      0.97    298069\n",
      "\n",
      "[[283520  11280]\n",
      " [  2040   1229]]\n",
      "0.9553123605608097\n",
      "0.09824926053241666\n",
      "0.37595594983175284\n",
      "0.15578653821777158\n",
      "0.8725704481845618\n",
      "0.12528700350742578\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_train_resampled).items()))\n",
    "\n",
    "#---------------------------------------------\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with precision, recall, and AUC metrics\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[Precision(), Recall(), AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Create a Custom Callback for AUC-PR\n",
    "\n",
    "class AUC_PR(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super(AUC_PR, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "        val_targ = self.validation_data[1]\n",
    "        precision, recall, _ = precision_recall_curve(val_targ, val_predict)\n",
    "        auc_pr = auc(recall, precision)\n",
    "        print(f' - val_auc_pr: {auc_pr:.4f}')\n",
    "        logs['val_auc_pr'] = auc_pr\n",
    "\n",
    "# Train the Model with the Custom Callback\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_resampled, y_train_resampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define early stopping and custom AUC-PR callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "auc_pr_callback = AUC_PR(validation_data=(X_val_split, y_val_split))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_split, y_train_split,\n",
    "    epochs=100,\n",
    "    batch_size=32,    # limit of memory, also the running speed\n",
    "    validation_data=(X_val_split, y_val_split),\n",
    "    callbacks=[early_stopping, auc_pr_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on the test data\n",
    "results = model.evaluate(X_test, y_test)\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(f\"{name}: {value}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#--------------------------------------\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(roc_auc_score(y_test, y_score))\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "print(auc(recall, precision))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

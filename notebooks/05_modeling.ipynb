{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Load previously processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediate data was saved as '../data/baf_cat_dummy_na_median_num_scaled.csv.gz' previously.\n",
    "baf_data = pd.read_csv('../data/baf_cat_dummy_na_median_num_scaled.csv.gz', compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 993563 entries, 0 to 993562\n",
      "Data columns (total 53 columns):\n",
      " #   Column                            Non-Null Count   Dtype  \n",
      "---  ------                            --------------   -----  \n",
      " 0   fraud_bool                        993563 non-null  int64  \n",
      " 1   email_is_free                     993563 non-null  int64  \n",
      " 2   phone_home_valid                  993563 non-null  int64  \n",
      " 3   phone_mobile_valid                993563 non-null  int64  \n",
      " 4   has_other_cards                   993563 non-null  int64  \n",
      " 5   foreign_request                   993563 non-null  int64  \n",
      " 6   keep_alive_session                993563 non-null  int64  \n",
      " 7   payment_type_AA                   993563 non-null  int64  \n",
      " 8   payment_type_AB                   993563 non-null  int64  \n",
      " 9   payment_type_AC                   993563 non-null  int64  \n",
      " 10  payment_type_AD                   993563 non-null  int64  \n",
      " 11  payment_type_AE                   993563 non-null  int64  \n",
      " 12  employment_status_CA              993563 non-null  int64  \n",
      " 13  employment_status_CB              993563 non-null  int64  \n",
      " 14  employment_status_CC              993563 non-null  int64  \n",
      " 15  employment_status_CD              993563 non-null  int64  \n",
      " 16  employment_status_CE              993563 non-null  int64  \n",
      " 17  employment_status_CF              993563 non-null  int64  \n",
      " 18  employment_status_CG              993563 non-null  int64  \n",
      " 19  housing_status_BA                 993563 non-null  int64  \n",
      " 20  housing_status_BB                 993563 non-null  int64  \n",
      " 21  housing_status_BC                 993563 non-null  int64  \n",
      " 22  housing_status_BD                 993563 non-null  int64  \n",
      " 23  housing_status_BE                 993563 non-null  int64  \n",
      " 24  housing_status_BF                 993563 non-null  int64  \n",
      " 25  housing_status_BG                 993563 non-null  int64  \n",
      " 26  source_INTERNET                   993563 non-null  int64  \n",
      " 27  source_TELEAPP                    993563 non-null  int64  \n",
      " 28  device_os_linux                   993563 non-null  int64  \n",
      " 29  device_os_macintosh               993563 non-null  int64  \n",
      " 30  device_os_other                   993563 non-null  int64  \n",
      " 31  device_os_windows                 993563 non-null  int64  \n",
      " 32  device_os_x11                     993563 non-null  int64  \n",
      " 33  intended_balcon_amount_negative   993563 non-null  int64  \n",
      " 34  income                            993563 non-null  float64\n",
      " 35  name_email_similarity             993563 non-null  float64\n",
      " 36  prev_address_months_count         993563 non-null  float64\n",
      " 37  current_address_months_count      993563 non-null  float64\n",
      " 38  customer_age                      993563 non-null  float64\n",
      " 39  days_since_request                993563 non-null  float64\n",
      " 40  intended_balcon_amount            993563 non-null  float64\n",
      " 41  zip_count_4w                      993563 non-null  float64\n",
      " 42  velocity_6h                       993563 non-null  float64\n",
      " 43  velocity_24h                      993563 non-null  float64\n",
      " 44  velocity_4w                       993563 non-null  float64\n",
      " 45  bank_branch_count_8w              993563 non-null  float64\n",
      " 46  date_of_birth_distinct_emails_4w  993563 non-null  float64\n",
      " 47  credit_risk_score                 993563 non-null  float64\n",
      " 48  bank_months_count                 993563 non-null  float64\n",
      " 49  proposed_credit_limit             993563 non-null  float64\n",
      " 50  session_length_in_minutes         993563 non-null  float64\n",
      " 51  device_distinct_emails_8w         993563 non-null  float64\n",
      " 52  month                             993563 non-null  float64\n",
      "dtypes: float64(19), int64(34)\n",
      "memory usage: 401.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Validate data types and non-null values.\n",
    "baf_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Split data into training and testing subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the features will be used for modeling at the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(baf_data.drop(columns='fraud_bool'), baf_data.fraud_bool, test_size=0.3, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((695494, 52), (298069, 52))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((695494,), (298069,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Applying the Machine Learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraud or not is a classification problem. The following supervised learning classification models will be used:\n",
    "\n",
    "- Logistic Regression\n",
    "- K-Nearest Neighbor (KNN)\n",
    "- Random Forest\n",
    "- Support vector machine (SVM)\n",
    "- Naive Bayes\n",
    "- Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation metrics, F1 score, Recall, Precision, ROC AUC, PR AUC will be calculated and compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294774     26]\n",
      " [  3231     38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.59      0.01      0.02      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.79      0.51      0.51    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "   C_parameter Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0            1       0.989073         0.59375     0.011624  0.022802   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.871519  0.130022  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# First we will try LogisticRegresssion model without considering the class_weight\n",
    "\n",
    "table = pd.DataFrame(columns = ['C_parameter','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['C_parameter'] = [1]\n",
    "\n",
    "# Apply logistic regression model to training data\n",
    "logreg = LogisticRegression(penalty='l2', C=1, class_weight=None, random_state=47, max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score 0.022 is very poor. Would it be related to inbalanced classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud_bool\n",
      "0    982568\n",
      "1     10995\n",
      "Name: count, dtype: int64\n",
      "fraud_bool=1 of all ratio:  0.011\n",
      "fraud_bool=0 of all ratio:  0.989\n"
     ]
    }
   ],
   "source": [
    "# Print target column `fraud_bool` value count\n",
    "print(baf_data['fraud_bool'].value_counts())\n",
    "# Print the pencentage of fraud instances of all records\n",
    "fraud_bool_1 = len(baf_data[baf_data['fraud_bool']==1]) / len(baf_data)\n",
    "fraud_bool_0 = len(baf_data[baf_data['fraud_bool']==0]) / len(baf_data)\n",
    "print(f'fraud_bool=1 of all ratio: {fraud_bool_1: .3f}')\n",
    "print(f'fraud_bool=0 of all ratio: {fraud_bool_0: .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the fraud ratio is very low, only 1.1% of all in baf_data. Next we are going to try class_weight='balanced' in the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[237180  57620]\n",
      " [   716   2553]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89    294800\n",
      "           1       0.04      0.78      0.08      3269\n",
      "\n",
      "    accuracy                           0.80    298069\n",
      "   macro avg       0.52      0.79      0.49    298069\n",
      "weighted avg       0.99      0.80      0.88    298069\n",
      "\n",
      "   C_parameter Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0            1       0.804287        0.042428     0.780973  0.080483   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0       0.87257  0.125287  \n"
     ]
    }
   ],
   "source": [
    "# Try the built in class_weight='balanced'\n",
    "\n",
    "table = pd.DataFrame(columns = ['C_parameter','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['C_parameter'] = [1]\n",
    "\n",
    "# Apply logistic regression model to training data\n",
    "logreg = LogisticRegression(penalty='l2', C=1, class_weight='balanced', random_state=47, max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the built in 'balanced' class_weight, Recall score increased to 0.78, but Precision decreased to 0.04 as false positive number also increased a lot. F1 score improved to 0.08, better still poor. Accuracy score and roc_auc score doesn't seem to be good choices for inbalanced data classification in the current model. F1 score and pr_auc may be more useful metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(max_iter=100000, random_state=47),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;class_weight&#x27;: [{0: 0.001, 1: 0.999},\n",
       "                                          {0: 0.005, 1: 0.995},\n",
       "                                          {0: 0.01, 1: 0.99},\n",
       "                                          {0: 0.02, 1: 0.98}, {0: 0.1, 1: 0.9},\n",
       "                                          {0: 0.2, 1: 0.8}],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;, &#x27;newton-cholesky&#x27;,\n",
       "                                    &#x27;sag&#x27;, &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(max_iter=100000, random_state=47),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;class_weight&#x27;: [{0: 0.001, 1: 0.999},\n",
       "                                          {0: 0.005, 1: 0.995},\n",
       "                                          {0: 0.01, 1: 0.99},\n",
       "                                          {0: 0.02, 1: 0.98}, {0: 0.1, 1: 0.9},\n",
       "                                          {0: 0.2, 1: 0.8}],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;, &#x27;newton-cholesky&#x27;,\n",
       "                                    &#x27;sag&#x27;, &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=100000, random_state=47)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=100000, random_state=47)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(max_iter=100000, random_state=47),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'class_weight': [{0: 0.001, 1: 0.999},\n",
       "                                          {0: 0.005, 1: 0.995},\n",
       "                                          {0: 0.01, 1: 0.99},\n",
       "                                          {0: 0.02, 1: 0.98}, {0: 0.1, 1: 0.9},\n",
       "                                          {0: 0.2, 1: 0.8}],\n",
       "                         'solver': ['lbfgs', 'newton-cg', 'newton-cholesky',\n",
       "                                    'sag', 'saga']},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter GridSearch for better parameters.\n",
    "# penalty, C, class_weight, and solver will be tried.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'class_weight': [{0:0.001, 1:0.999}, {0:0.005, 1:0.995}, {0:0.01, 1:0.99}, \n",
    "                               {0:0.02, 1:0.98}, {0:0.1, 1:0.9}, {0:0.2, 1:0.8}], \n",
    "              'solver': ['lbfgs', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "              }\n",
    "\n",
    "logreg = LogisticRegression(penalty='l2', random_state=47, max_iter=100000)\n",
    "\n",
    "cv = GridSearchCV(logreg, param_grid, scoring='f1', cv=5, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.21037044297173818\n",
      "Best parameters: {'C': 0.1, 'class_weight': {0: 0.1, 1: 0.9}, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best score: {cv.best_score_}')\n",
    "print(f'Best parameters: {cv.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, class_weight={0: 0.1, 1: 0.9}, max_iter=100000,\n",
       "                   random_state=47)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, class_weight={0: 0.1, 1: 0.9}, max_iter=100000,\n",
       "                   random_state=47)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight={0: 0.1, 1: 0.9}, max_iter=100000,\n",
       "                   random_state=47)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the best parameters found by GridSearchCV to apply logistic regression model for result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[290355   4445]\n",
      " [  2403    866]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99    294800\n",
      "           1       0.16      0.26      0.20      3269\n",
      "\n",
      "    accuracy                           0.98    298069\n",
      "   macro avg       0.58      0.62      0.60    298069\n",
      "weighted avg       0.98      0.98      0.98    298069\n",
      "\n",
      "   C_parameter Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0          0.1       0.977025        0.163058     0.264913  0.201865   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0       0.87209  0.128814  \n"
     ]
    }
   ],
   "source": [
    "# Use best parameters: {'C': 0.1, 'class_weight': {0: 0.1, 1: 0.9}, 'solver': 'lbfgs'}\n",
    "\n",
    "table = pd.DataFrame(columns = ['C_parameter','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['C_parameter'] = [0.1]\n",
    "\n",
    "# Apply logistic regression model to training data\n",
    "logreg = LogisticRegression(penalty='l2', C=0.1, class_weight={0: 0.1, 1: 0.9}, solver='lbfgs', random_state=47, max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While F1 score is 0.201, Recall and Precision are both low. Let's visulize the result the ROC curve and Precision Recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, thd = roc_curve(y_test, y_score)\n",
    "\n",
    "# ROC curve\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(fpr, tpr, marker='.', markersize=1.5, label='LogisticRegression')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Precision recall curve\n",
    "plt.plot([0, 1], [1, 0], linestyle='--')\n",
    "plt.plot(recall, precision, marker='.', markersize=1.5, label='LogisticRegression')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above two charts, we can see that ROC curve doesn't show the impact of class inbalance. Precision recall curve may be better to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 K-Nearest neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['n_neighbors','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['n_neighbors'] = [50]\n",
    "\n",
    "# Apply KNN model to the training data\n",
    "# knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2, metric='minkowski', n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "y_score = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems KNN modeling doesn't work well on the current data set. Is it possible for Recall and Precision bother to be 0? Need to discuss with Mentor and try different upsampling or different parameters with KNN and try again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294797      3]\n",
      " [  3263      6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.67      0.00      0.00      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.83      0.50      0.50    298069\n",
      "weighted avg       0.99      0.99      0.98    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0   entropy       0.989043        0.666667     0.001835  0.003661   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.832728  0.127872  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['criterion','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['criterion'] = ['entropy']\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "rfc = RandomForestClassifier(criterion='entropy', random_state=47, n_jobs=-1, class_weight='balanced')\n",
    "# max-splits: 8 or less than 10, 2 or 3\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Precision recall curve\n",
    "plt.plot([0, 1], [1, 0], linestyle='--')\n",
    "plt.plot(recall, precision, marker='.', markersize=1.5, label='RandomForestClassifier')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation train scores: [0.00258398 0.00129366 0.00773694 0.00129116 0.00514801]\n",
      "Mean cross validation train score: 0.0036107490056754336\n",
      "Standard deviation of cv train scores: 0.0024976912126122267\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores_train= cross_val_score(rfc, X_train, y_train, scoring='f1', cv=5, n_jobs=-1)\n",
    "# cv_scores_test= cross_val_score(rfc, X_test, y_test, scoring='f1', cv=5, n_jobs=-1)\n",
    "print(f'cross validation train scores: {cv_scores_train}')\n",
    "# print(f'cross validation test scores: {cv_scores_test}')\n",
    "cv_scores_rf_train= cv_scores_train.mean()\n",
    "# cv_scores_rf_test= cv_scores_test.mean()\n",
    "cv_scores_rf_train_std= cv_scores_train.std()\n",
    "# cv_scores_std_rf= cv_scores_test.std()\n",
    "print (f'Mean cross validation train score: {cv_scores_rf_train}')\n",
    "print (f'Standard deviation of cv train scores: {cv_scores_rf_train_std}')\n",
    "# print (f'Mean cross validation test score: {cv_scores_rf_test}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using F1 score as the metrics, the cross validation scores on train data varied with relatively big deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.3-2 Random Forest model with some constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[247194  47606]\n",
      " [   842   2427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91    294800\n",
      "           1       0.05      0.74      0.09      3269\n",
      "\n",
      "    accuracy                           0.84    298069\n",
      "   macro avg       0.52      0.79      0.50    298069\n",
      "weighted avg       0.99      0.84      0.90    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0   entropy        0.83746        0.048508     0.742429  0.091066   \n",
      "\n",
      "  roc_auc_score  pr_auc  \n",
      "0      0.874927  0.1286  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['criterion','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['criterion'] = ['entropy']\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, random_state=47, n_jobs=-1, class_weight='balanced')\n",
    "# max-splits: 8 or less than 10, 2 or 3\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Precision recall curve\n",
    "plt.plot([0, 1], [1, 0], linestyle='--')\n",
    "plt.plot(recall, precision, marker='.', markersize=1.5, label='RandomForestClassifier')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.4 Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[293355   1445]\n",
      " [  3068    201]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.12      0.06      0.08      3269\n",
      "\n",
      "    accuracy                           0.98    298069\n",
      "   macro avg       0.56      0.53      0.54    298069\n",
      "weighted avg       0.98      0.98      0.98    298069\n",
      "\n",
      "              model Accuracy_score Precision_score Recall_score F1_score  \\\n",
      "0  GradientBoosting       0.984859        0.122114     0.061487  0.08179   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.877752  0.089802  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['model','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['model'] = ['GradientBoosting']\n",
    "\n",
    "gbc = GradientBoostingClassifier(learning_rate=0.1, n_estimators=150, subsample=0.8, max_depth=10, random_state=47)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = gbc.predict(X_test)\n",
    "y_score = gbc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Precision recall curve\n",
    "plt.plot([0, 1], [1, 0], linestyle='--')\n",
    "plt.plot(recall, precision, marker='.', markersize=1.5, label='GradientBoosting')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation train scores: [0.0793177  0.07705479 0.07017544 0.07839795 0.08490963]\n",
      "Mean cross validation train score: 0.07797110221487549\n",
      "Standard deviation of cv train scores: 0.0047275918429300545\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_scores_train= cross_val_score(gbc, X_train, y_train, scoring='f1', cv=5, n_jobs=-1)\n",
    "# cv_scores_test= cross_val_score(gbc, X_test, y_test, scoring='f1', cv=5, n_jobs=-1)\n",
    "print(f'cross validation train scores: {cv_scores_train}')\n",
    "# print(f'cross validation test scores: {cv_scores_test}')\n",
    "cv_scores_rf_train= cv_scores_train.mean()\n",
    "# cv_scores_rf_test= cv_scores_test.mean()\n",
    "cv_scores_rf_train_std= cv_scores_train.std()\n",
    "# cv_scores_std_rf= cv_scores_test.std()\n",
    "print (f'Mean cross validation train score: {cv_scores_rf_train}')\n",
    "print (f'Standard deviation of cv train scores: {cv_scores_rf_train_std}')\n",
    "# print (f'Mean cross validation test score: {cv_scores_rf_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Modeling with resampled training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 Random over-sampling of fraud data in training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 687768), (1, 687768)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print(sorted(Counter(y_train_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 Random Forest model with some constraints and resampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[244414  50386]\n",
      " [   795   2474]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91    294800\n",
      "           1       0.05      0.76      0.09      3269\n",
      "\n",
      "    accuracy                           0.83    298069\n",
      "   macro avg       0.52      0.79      0.50    298069\n",
      "weighted avg       0.99      0.83      0.90    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0   entropy       0.828291        0.046803     0.756806  0.088154   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.875507  0.129525  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['criterion','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['criterion'] = ['entropy']\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, random_state=47, n_jobs=-1)\n",
    "\n",
    "rfc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.3 Combination of over and under resampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "# print(sorted(Counter(y_train_resampled).items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 608306), (1, 687768)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[258729  36071]\n",
      " [  1084   2185]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93    294800\n",
      "           1       0.06      0.67      0.11      3269\n",
      "\n",
      "    accuracy                           0.88    298069\n",
      "   macro avg       0.53      0.77      0.52    298069\n",
      "weighted avg       0.99      0.88      0.92    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0   entropy       0.875348        0.057115       0.6684  0.105238   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.869108  0.113453  \n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['criterion','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['criterion'] = ['entropy']\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, random_state=47, n_jobs=-1)\n",
    "\n",
    "rfc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.4 Under resampling of not fraud type training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 7726), (1, 7726)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(sorted(Counter(y_train_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[239652  55148]\n",
      " [   747   2522]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.90    294800\n",
      "           1       0.04      0.77      0.08      3269\n",
      "\n",
      "    accuracy                           0.81    298069\n",
      "   macro avg       0.52      0.79      0.49    298069\n",
      "weighted avg       0.99      0.81      0.89    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0   entropy       0.812476        0.043732      0.77149  0.082771   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.873721  0.132063  \n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['criterion','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['criterion'] = ['entropy']\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, random_state=47, n_jobs=-1)\n",
    "\n",
    "rfc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.5 Under resampling of not fraud type training data, Prototype generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ematrix/miniconda3/envs/notebook/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 7726), (1, 7726)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids(random_state=42)\n",
    "X_train_resampled, y_train_resampled = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "print(sorted(Counter(y_train_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    20 294780]\n",
      " [     0   3269]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00    294800\n",
      "           1       0.01      1.00      0.02      3269\n",
      "\n",
      "    accuracy                           0.01    298069\n",
      "   macro avg       0.51      0.50      0.01    298069\n",
      "weighted avg       0.99      0.01      0.00    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0   entropy       0.011034        0.010968          1.0  0.021698   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.720985  0.089162  \n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['criterion','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['criterion'] = ['entropy']\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, random_state=47, n_jobs=-1)\n",
    "\n",
    "rfc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.6 The Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 687768), (1, 687768)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_train_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.6.1 RandomForest Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[265789  29011]\n",
      " [  1287   1982]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95    294800\n",
      "           1       0.06      0.61      0.12      3269\n",
      "\n",
      "    accuracy                           0.90    298069\n",
      "   macro avg       0.53      0.75      0.53    298069\n",
      "weighted avg       0.98      0.90      0.94    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0   entropy       0.898352         0.06395     0.606302  0.115697   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.866954  0.112036  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['criterion','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['criterion'] = ['entropy']\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, random_state=47, n_jobs=-1)\n",
    "\n",
    "rfc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.6.2 XGboost Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294287    513]\n",
      " [  2996    273]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.35      0.08      0.13      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.67      0.54      0.56    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0       xgb       0.988228        0.347328     0.083512  0.134649   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.878641  0.141921  \n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['criterion','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['criterion'] = ['xgb']\n",
    "\n",
    "# \n",
    "xgb = XGBClassifier(objective='binary:logistic', seed=74, eval_metric='aucpr')\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_score = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.6.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[222956  71844]\n",
      " [   945   2324]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.86    294800\n",
      "           1       0.03      0.71      0.06      3269\n",
      "\n",
      "    accuracy                           0.76    298069\n",
      "   macro avg       0.51      0.73      0.46    298069\n",
      "weighted avg       0.99      0.76      0.85    298069\n",
      "\n",
      "   n_neighbors Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0           50       0.755798        0.031334     0.710921  0.060023   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.801767  0.084731  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['n_neighbors','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['n_neighbors'] = [50]\n",
    "\n",
    "# Apply KNN model to the training data\n",
    "# knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2, metric='minkowski', n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2)\n",
    "knn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "y_score = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.6.4 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[281414  13386]\n",
      " [  1897   1372]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    294800\n",
      "           1       0.09      0.42      0.15      3269\n",
      "\n",
      "    accuracy                           0.95    298069\n",
      "   macro avg       0.54      0.69      0.56    298069\n",
      "weighted avg       0.98      0.95      0.96    298069\n",
      "\n",
      "   C_parameter Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0          0.1       0.948727        0.092967       0.4197  0.152216   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.845516  0.103601  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "table = pd.DataFrame(columns = ['C_parameter','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['C_parameter'] = [0.1]\n",
    "\n",
    "# Apply logistic regression model to training data\n",
    "logreg = LogisticRegression(penalty='l2', C=0.1, solver='lbfgs', random_state=47, max_iter=1000)\n",
    "logreg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.7 Under-sampling with RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 7726), (1, 7726)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(sorted(Counter(y_train_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.7.1 RandomForest Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[239652  55148]\n",
      " [   747   2522]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.90    294800\n",
      "           1       0.04      0.77      0.08      3269\n",
      "\n",
      "    accuracy                           0.81    298069\n",
      "   macro avg       0.52      0.79      0.49    298069\n",
      "weighted avg       0.99      0.81      0.89    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0   entropy       0.812476        0.043732      0.77149  0.082771   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.873721  0.132063  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['criterion','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['criterion'] = ['entropy']\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, random_state=47, n_jobs=-1)\n",
    "\n",
    "rfc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.7.2 XGboost Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[238011  56789]\n",
      " [   676   2593]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.89    294800\n",
      "           1       0.04      0.79      0.08      3269\n",
      "\n",
      "    accuracy                           0.81    298069\n",
      "   macro avg       0.52      0.80      0.49    298069\n",
      "weighted avg       0.99      0.81      0.88    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0       xgb       0.807209        0.043666     0.793209  0.082776   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.881439  0.135744  \n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['criterion','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['criterion'] = ['xgb']\n",
    "\n",
    "# \n",
    "xgb = XGBClassifier(objective='binary:logistic', seed=74, eval_metric='aucpr')\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_score = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.7.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[217780  77020]\n",
      " [   710   2559]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.74      0.85    294800\n",
      "           1       0.03      0.78      0.06      3269\n",
      "\n",
      "    accuracy                           0.74    298069\n",
      "   macro avg       0.51      0.76      0.46    298069\n",
      "weighted avg       0.99      0.74      0.84    298069\n",
      "\n",
      "   n_neighbors Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0           50       0.739221        0.032157     0.782808  0.061776   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0        0.8365  0.083528  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['n_neighbors','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['n_neighbors'] = [50]\n",
    "\n",
    "# Apply KNN model to the training data\n",
    "# knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2, metric='minkowski', n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2)\n",
    "knn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "y_score = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.7.4 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[237651  57149]\n",
      " [   726   2543]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.89    294800\n",
      "           1       0.04      0.78      0.08      3269\n",
      "\n",
      "    accuracy                           0.81    298069\n",
      "   macro avg       0.52      0.79      0.49    298069\n",
      "weighted avg       0.99      0.81      0.88    298069\n",
      "\n",
      "   C_parameter Accuracy_score Precision_score Recall_score F1_score  \\\n",
      "0          0.1       0.805834        0.042602     0.777914  0.08078   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.872246  0.125622  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "table = pd.DataFrame(columns = ['C_parameter','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['C_parameter'] = [0.1]\n",
    "\n",
    "# Apply logistic regression model to training data\n",
    "logreg = LogisticRegression(penalty='l2', C=0.1, solver='lbfgs', random_state=47, max_iter=1000)\n",
    "logreg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.8 Under-sampling by removing Tomek’s links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 685578), (1, 7726)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks(n_jobs=-1)\n",
    "X_train_resampled, y_train_resampled = tl.fit_resample(X_train, y_train)\n",
    "\n",
    "print(sorted(Counter(y_train_resampled).items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.8.1 RandomForest Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[246382  48418]\n",
      " [   842   2427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91    294800\n",
      "           1       0.05      0.74      0.09      3269\n",
      "\n",
      "    accuracy                           0.83    298069\n",
      "   macro avg       0.52      0.79      0.50    298069\n",
      "weighted avg       0.99      0.83      0.90    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score F1_score  \\\n",
      "0   entropy       0.834736        0.047733     0.742429   0.0897   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.873076  0.127794  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['criterion','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['criterion'] = ['entropy']\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "# Add class_weight='balanced'\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, class_weight='balanced', random_state=47, n_jobs=-1)\n",
    "\n",
    "rfc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.8.2 XGboost Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294604    196]\n",
      " [  3111    158]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.45      0.05      0.09      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.72      0.52      0.54    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0       xgb       0.988905        0.446328     0.048333  0.087221   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.885752  0.154913  \n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['criterion','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['criterion'] = ['xgb']\n",
    "\n",
    "# \n",
    "xgb = XGBClassifier(objective='binary:logistic', seed=74, eval_metric='aucpr')\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_score = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.8.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294800      0]\n",
      " [  3268      1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       1.00      0.00      0.00      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.99      0.50      0.50    298069\n",
      "weighted avg       0.99      0.99      0.98    298069\n",
      "\n",
      "   n_neighbors Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0           50       0.989036             1.0     0.000306  0.000612   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.771262  0.093185  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['n_neighbors','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['n_neighbors'] = [50]\n",
    "\n",
    "# Apply KNN model to the training data\n",
    "# knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2, metric='minkowski', n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2)\n",
    "knn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "y_score = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.8.4 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294772     28]\n",
      " [  3229     40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.59      0.01      0.02      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.79      0.51      0.51    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "   C_parameter Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0          0.1       0.989073        0.588235     0.012236  0.023974   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.871424  0.130207  \n"
     ]
    }
   ],
   "source": [
    "table = pd.DataFrame(columns = ['C_parameter','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['C_parameter'] = [0.1]\n",
    "\n",
    "# Apply logistic regression model to training data\n",
    "logreg = LogisticRegression(penalty='l2', C=0.1, solver='lbfgs', random_state=47, max_iter=1000)\n",
    "logreg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.9 Under-sampling by EditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 667924), (1, 7726)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "enn = EditedNearestNeighbours(n_neighbors=3, n_jobs=-1)\n",
    "X_train_resampled, y_train_resampled = enn.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_train_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.9.1 RandomForest Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[246942  47858]\n",
      " [   840   2429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91    294800\n",
      "           1       0.05      0.74      0.09      3269\n",
      "\n",
      "    accuracy                           0.84    298069\n",
      "   macro avg       0.52      0.79      0.50    298069\n",
      "weighted avg       0.99      0.84      0.90    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0   entropy       0.836622        0.048303     0.743041  0.090709   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.873774  0.126791  \n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['criterion','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['criterion'] = ['entropy']\n",
    "\n",
    "# Apply RandomForestClassifier to training data\n",
    "# Add class_weight='balanced'\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, class_weight='balanced', random_state=47, n_jobs=-1)\n",
    "\n",
    "rfc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_score = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.9.2 XGboost Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294387    413]\n",
      " [  2994    275]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.40      0.08      0.14      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.69      0.54      0.57    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "  criterion Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0       xgb        0.98857        0.399709     0.084124  0.138994   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.889849  0.160301  \n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "table = pd.DataFrame(columns = ['criterion','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['criterion'] = ['xgb']\n",
    "\n",
    "# \n",
    "xgb = XGBClassifier(objective='binary:logistic', seed=74, eval_metric='aucpr')\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_score = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.9.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294793      7]\n",
      " [  3256     13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.65      0.00      0.01      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.82      0.50      0.50    298069\n",
      "weighted avg       0.99      0.99      0.98    298069\n",
      "\n",
      "   n_neighbors Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0           50       0.989053            0.65     0.003977  0.007905   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.774667  0.096543  \n"
     ]
    }
   ],
   "source": [
    "table = pd.DataFrame(columns = ['n_neighbors','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['n_neighbors'] = [50]\n",
    "\n",
    "# Apply KNN model to the training data\n",
    "# knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2, metric='minkowski', n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_neighbors=50, weights='distance', p=2)\n",
    "knn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "y_score = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.9.4 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294705     95]\n",
      " [  3184     85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.47      0.03      0.05      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.73      0.51      0.52    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "   C_parameter Accuracy_score Precision_score Recall_score F1_score  \\\n",
      "0          0.1       0.988999        0.472222     0.026002  0.04929   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.871013  0.130367  \n"
     ]
    }
   ],
   "source": [
    "table = pd.DataFrame(columns = ['C_parameter','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['C_parameter'] = [0.1]\n",
    "\n",
    "# Apply logistic regression model to training data\n",
    "logreg = LogisticRegression(penalty='l2', C=0.1, solver='lbfgs', random_state=47, max_iter=1000)\n",
    "logreg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and save to y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_score = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print score values\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5.10 Stacking modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294770     30]\n",
      " [  3233     36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.55      0.01      0.02      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.77      0.51      0.51    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as Pipeline_imb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_xgb = Pipeline_imb([\n",
    "    ('rus', RandomUnderSampler(random_state=42)), \n",
    "    ('model_1', XGBClassifier(objective='binary:logistic', seed=74, eval_metric='aucpr', n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipe_knn = Pipeline_imb([\n",
    "    ('enn', EditedNearestNeighbours(n_neighbors=3, n_jobs=-1)), \n",
    "    ('model_2', KNeighborsClassifier(n_neighbors=50, weights='distance', p=2, n_jobs=-1))\n",
    "])\n",
    "\n",
    "level0 = list()\n",
    "level0.append(('xgboost', pipe_xgb))\n",
    "level0.append(('knn', pipe_knn))\n",
    "\n",
    "level1 = LogisticRegression(random_state=74, n_jobs=-1)\n",
    "\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_score = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "table = pd.DataFrame(columns = ['model','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['model'] = ['stacking']\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      model Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0  stacking       0.989053        0.545455     0.011013  0.021589   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.881819  0.129291  \n"
     ]
    }
   ],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294740     60]\n",
      " [  3207     62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.51      0.02      0.04      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.75      0.51      0.52    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "      model Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0  stacking       0.989039        0.508197     0.018966  0.036567   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.884291  0.144066  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from imblearn.pipeline import Pipeline as Pipeline_imb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_xgb = Pipeline_imb([\n",
    "    ('rus', RandomUnderSampler(random_state=42)), \n",
    "    ('model_1', XGBClassifier(objective='binary:logistic', seed=74, eval_metric='aucpr', n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipe_lgb = Pipeline_imb([\n",
    "    ('tl', TomekLinks(n_jobs=-1)), \n",
    "    ('model_2', LogisticRegression(penalty='l2', C=0.1, solver='lbfgs', random_state=47, max_iter=1000, n_jobs=-1))\n",
    "])\n",
    "\n",
    "level0 = list()\n",
    "level0.append(('xgboost', pipe_xgb))\n",
    "level0.append(('lbg', pipe_lgb))\n",
    "\n",
    "level1 = LogisticRegression(random_state=74, n_jobs=-1)\n",
    "\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_score = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "table = pd.DataFrame(columns = ['model','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['model'] = ['stacking']\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294699    101]\n",
      " [  3144    125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    294800\n",
      "           1       0.55      0.04      0.07      3269\n",
      "\n",
      "    accuracy                           0.99    298069\n",
      "   macro avg       0.77      0.52      0.53    298069\n",
      "weighted avg       0.98      0.99      0.98    298069\n",
      "\n",
      "      model Accuracy_score Precision_score Recall_score  F1_score  \\\n",
      "0  stacking       0.989113        0.553097     0.038238  0.071531   \n",
      "\n",
      "  roc_auc_score    pr_auc  \n",
      "0      0.877583  0.153836  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from imblearn.pipeline import Pipeline as Pipeline_imb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_rfc = Pipeline_imb([\n",
    "    ('rus', RandomUnderSampler(random_state=42)), \n",
    "    ('model_1', RandomForestClassifier(criterion='entropy', max_depth=8, min_samples_split=2, max_features=4, random_state=47, n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipe_xgb = Pipeline_imb([\n",
    "    ('tl', TomekLinks(n_jobs=-1)), \n",
    "    ('model_2', XGBClassifier(objective='binary:logistic', seed=74, eval_metric='aucpr', n_jobs=-1))\n",
    "])\n",
    "\n",
    "level0 = list()\n",
    "level0.append(('rfc', pipe_rfc))\n",
    "level0.append(('xgb', pipe_xgb))\n",
    "\n",
    "level1 = LogisticRegression(random_state=74, n_jobs=-1)\n",
    "\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_score = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "table = pd.DataFrame(columns = ['model','Accuracy_score', 'Precision_score', 'Recall_score', 'F1_score', 'roc_auc_score', 'pr_auc'])\n",
    "table['model'] = ['stacking']\n",
    "\n",
    "# Save score values in table\n",
    "table.iloc[0, 1] = accuracy_score(y_test, y_pred)\n",
    "table.iloc[0, 2] = precision_score(y_test, y_pred)\n",
    "table.iloc[0, 3] = recall_score(y_test, y_pred)\n",
    "table.iloc[0, 4] = f1_score(y_test, y_pred)\n",
    "table.iloc[0, 5] = roc_auc_score(y_test, y_score)\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "table.iloc[0, 6] = auc(recall, precision)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.6 Neural network modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.6.1 Oversample the minority class with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 687768), (1, 687768)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_train_resampled).items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.6.2 Build the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shenj\\miniconda3\\envs\\datascience\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with precision, recall, and AUC metrics\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[Precision(), Recall(), AUC(name='auc')]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Custom Callback for AUC-PR\n",
    "\n",
    "class AUC_PR(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super(AUC_PR, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "        val_targ = self.validation_data[1]\n",
    "        precision, recall, _ = precision_recall_curve(val_targ, val_predict)\n",
    "        auc_pr = auc(recall, precision)\n",
    "        print(f' - val_auc_pr: {auc_pr:.4f}')\n",
    "        logs['val_auc_pr'] = auc_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9920\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 3ms/step - auc: 0.9673 - loss: 0.2146 - precision: 0.9184 - recall: 0.9096 - val_auc: 0.9910 - val_loss: 0.1186 - val_precision: 0.9629 - val_recall: 0.9421 - val_auc_pr: 0.9920\n",
      "Epoch 2/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9926\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3ms/step - auc: 0.9879 - loss: 0.1364 - precision: 0.9570 - recall: 0.9392 - val_auc: 0.9915 - val_loss: 0.1139 - val_precision: 0.9612 - val_recall: 0.9490 - val_auc_pr: 0.9926\n",
      "Epoch 3/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9927\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9886 - loss: 0.1320 - precision: 0.9577 - recall: 0.9420 - val_auc: 0.9917 - val_loss: 0.1127 - val_precision: 0.9625 - val_recall: 0.9487 - val_auc_pr: 0.9927\n",
      "Epoch 4/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9929\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3ms/step - auc: 0.9889 - loss: 0.1305 - precision: 0.9581 - recall: 0.9429 - val_auc: 0.9919 - val_loss: 0.1112 - val_precision: 0.9638 - val_recall: 0.9482 - val_auc_pr: 0.9929\n",
      "Epoch 5/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9929\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9891 - loss: 0.1288 - precision: 0.9578 - recall: 0.9441 - val_auc: 0.9919 - val_loss: 0.1124 - val_precision: 0.9673 - val_recall: 0.9428 - val_auc_pr: 0.9929\n",
      "Epoch 6/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9931\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3ms/step - auc: 0.9892 - loss: 0.1282 - precision: 0.9577 - recall: 0.9449 - val_auc: 0.9922 - val_loss: 0.1099 - val_precision: 0.9597 - val_recall: 0.9547 - val_auc_pr: 0.9931\n",
      "Epoch 7/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9932\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9893 - loss: 0.1276 - precision: 0.9585 - recall: 0.9446 - val_auc: 0.9921 - val_loss: 0.1096 - val_precision: 0.9625 - val_recall: 0.9521 - val_auc_pr: 0.9932\n",
      "Epoch 8/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9932\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 3ms/step - auc: 0.9895 - loss: 0.1271 - precision: 0.9578 - recall: 0.9462 - val_auc: 0.9922 - val_loss: 0.1094 - val_precision: 0.9652 - val_recall: 0.9484 - val_auc_pr: 0.9932\n",
      "Epoch 9/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9932\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - auc: 0.9896 - loss: 0.1257 - precision: 0.9587 - recall: 0.9460 - val_auc: 0.9922 - val_loss: 0.1090 - val_precision: 0.9646 - val_recall: 0.9503 - val_auc_pr: 0.9932\n",
      "Epoch 10/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9897 - loss: 0.1252 - precision: 0.9591 - recall: 0.9469 - val_auc: 0.9925 - val_loss: 0.1085 - val_precision: 0.9674 - val_recall: 0.9489 - val_auc_pr: 0.9934\n",
      "Epoch 11/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9933\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3ms/step - auc: 0.9897 - loss: 0.1256 - precision: 0.9589 - recall: 0.9468 - val_auc: 0.9924 - val_loss: 0.1086 - val_precision: 0.9661 - val_recall: 0.9487 - val_auc_pr: 0.9933\n",
      "Epoch 12/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9933\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9899 - loss: 0.1244 - precision: 0.9592 - recall: 0.9469 - val_auc: 0.9924 - val_loss: 0.1081 - val_precision: 0.9617 - val_recall: 0.9548 - val_auc_pr: 0.9933\n",
      "Epoch 13/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - auc: 0.9899 - loss: 0.1240 - precision: 0.9595 - recall: 0.9479 - val_auc: 0.9925 - val_loss: 0.1079 - val_precision: 0.9668 - val_recall: 0.9488 - val_auc_pr: 0.9934\n",
      "Epoch 14/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - auc: 0.9898 - loss: 0.1245 - precision: 0.9589 - recall: 0.9471 - val_auc: 0.9924 - val_loss: 0.1073 - val_precision: 0.9635 - val_recall: 0.9540 - val_auc_pr: 0.9934\n",
      "Epoch 15/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9897 - loss: 0.1258 - precision: 0.9585 - recall: 0.9467 - val_auc: 0.9925 - val_loss: 0.1069 - val_precision: 0.9638 - val_recall: 0.9537 - val_auc_pr: 0.9934\n",
      "Epoch 16/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3ms/step - auc: 0.9897 - loss: 0.1252 - precision: 0.9593 - recall: 0.9464 - val_auc: 0.9924 - val_loss: 0.1077 - val_precision: 0.9611 - val_recall: 0.9564 - val_auc_pr: 0.9934\n",
      "Epoch 17/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 3ms/step - auc: 0.9899 - loss: 0.1241 - precision: 0.9593 - recall: 0.9479 - val_auc: 0.9924 - val_loss: 0.1072 - val_precision: 0.9626 - val_recall: 0.9551 - val_auc_pr: 0.9934\n",
      "Epoch 18/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3ms/step - auc: 0.9899 - loss: 0.1239 - precision: 0.9597 - recall: 0.9483 - val_auc: 0.9925 - val_loss: 0.1076 - val_precision: 0.9668 - val_recall: 0.9496 - val_auc_pr: 0.9934\n",
      "Epoch 19/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 3ms/step - auc: 0.9899 - loss: 0.1243 - precision: 0.9596 - recall: 0.9477 - val_auc: 0.9924 - val_loss: 0.1068 - val_precision: 0.9634 - val_recall: 0.9557 - val_auc_pr: 0.9935\n",
      "Epoch 20/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9898 - loss: 0.1244 - precision: 0.9592 - recall: 0.9480 - val_auc: 0.9927 - val_loss: 0.1074 - val_precision: 0.9662 - val_recall: 0.9512 - val_auc_pr: 0.9935\n",
      "Epoch 21/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9899 - loss: 0.1235 - precision: 0.9590 - recall: 0.9488 - val_auc: 0.9925 - val_loss: 0.1070 - val_precision: 0.9673 - val_recall: 0.9497 - val_auc_pr: 0.9935\n",
      "Epoch 22/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1236 - precision: 0.9594 - recall: 0.9474 - val_auc: 0.9926 - val_loss: 0.1055 - val_precision: 0.9648 - val_recall: 0.9539 - val_auc_pr: 0.9936\n",
      "Epoch 23/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1234 - precision: 0.9591 - recall: 0.9487 - val_auc: 0.9926 - val_loss: 0.1069 - val_precision: 0.9680 - val_recall: 0.9484 - val_auc_pr: 0.9935\n",
      "Epoch 24/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9899 - loss: 0.1239 - precision: 0.9595 - recall: 0.9481 - val_auc: 0.9926 - val_loss: 0.1067 - val_precision: 0.9674 - val_recall: 0.9496 - val_auc_pr: 0.9935\n",
      "Epoch 25/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1232 - precision: 0.9602 - recall: 0.9483 - val_auc: 0.9927 - val_loss: 0.1056 - val_precision: 0.9658 - val_recall: 0.9526 - val_auc_pr: 0.9936\n",
      "Epoch 26/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3ms/step - auc: 0.9899 - loss: 0.1240 - precision: 0.9591 - recall: 0.9480 - val_auc: 0.9925 - val_loss: 0.1061 - val_precision: 0.9628 - val_recall: 0.9565 - val_auc_pr: 0.9935\n",
      "Epoch 27/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - auc: 0.9899 - loss: 0.1240 - precision: 0.9590 - recall: 0.9485 - val_auc: 0.9925 - val_loss: 0.1068 - val_precision: 0.9657 - val_recall: 0.9512 - val_auc_pr: 0.9935\n",
      "Epoch 28/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9900 - loss: 0.1234 - precision: 0.9595 - recall: 0.9490 - val_auc: 0.9927 - val_loss: 0.1073 - val_precision: 0.9675 - val_recall: 0.9511 - val_auc_pr: 0.9936\n",
      "Epoch 29/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - auc: 0.9899 - loss: 0.1239 - precision: 0.9596 - recall: 0.9489 - val_auc: 0.9927 - val_loss: 0.1060 - val_precision: 0.9668 - val_recall: 0.9515 - val_auc_pr: 0.9936\n",
      "Epoch 30/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9900 - loss: 0.1235 - precision: 0.9592 - recall: 0.9490 - val_auc: 0.9927 - val_loss: 0.1085 - val_precision: 0.9723 - val_recall: 0.9426 - val_auc_pr: 0.9936\n",
      "Epoch 31/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9899 - loss: 0.1240 - precision: 0.9597 - recall: 0.9477 - val_auc: 0.9926 - val_loss: 0.1056 - val_precision: 0.9624 - val_recall: 0.9577 - val_auc_pr: 0.9936\n",
      "Epoch 32/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9901 - loss: 0.1233 - precision: 0.9593 - recall: 0.9487 - val_auc: 0.9927 - val_loss: 0.1050 - val_precision: 0.9635 - val_recall: 0.9561 - val_auc_pr: 0.9936\n",
      "Epoch 33/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1224 - precision: 0.9592 - recall: 0.9498 - val_auc: 0.9927 - val_loss: 0.1063 - val_precision: 0.9640 - val_recall: 0.9556 - val_auc_pr: 0.9936\n",
      "Epoch 34/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1232 - precision: 0.9592 - recall: 0.9486 - val_auc: 0.9927 - val_loss: 0.1056 - val_precision: 0.9666 - val_recall: 0.9524 - val_auc_pr: 0.9936\n",
      "Epoch 35/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1236 - precision: 0.9590 - recall: 0.9486 - val_auc: 0.9926 - val_loss: 0.1054 - val_precision: 0.9641 - val_recall: 0.9551 - val_auc_pr: 0.9936\n",
      "Epoch 36/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1237 - precision: 0.9589 - recall: 0.9485 - val_auc: 0.9927 - val_loss: 0.1067 - val_precision: 0.9650 - val_recall: 0.9536 - val_auc_pr: 0.9936\n",
      "Epoch 37/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1231 - precision: 0.9601 - recall: 0.9481 - val_auc: 0.9925 - val_loss: 0.1062 - val_precision: 0.9658 - val_recall: 0.9530 - val_auc_pr: 0.9936\n",
      "Epoch 38/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1228 - precision: 0.9590 - recall: 0.9486 - val_auc: 0.9926 - val_loss: 0.1056 - val_precision: 0.9638 - val_recall: 0.9564 - val_auc_pr: 0.9936\n",
      "Epoch 39/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1221 - precision: 0.9591 - recall: 0.9497 - val_auc: 0.9927 - val_loss: 0.1058 - val_precision: 0.9664 - val_recall: 0.9522 - val_auc_pr: 0.9936\n",
      "Epoch 40/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1230 - precision: 0.9591 - recall: 0.9493 - val_auc: 0.9926 - val_loss: 0.1053 - val_precision: 0.9623 - val_recall: 0.9583 - val_auc_pr: 0.9936\n",
      "Epoch 41/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1227 - precision: 0.9590 - recall: 0.9497 - val_auc: 0.9926 - val_loss: 0.1058 - val_precision: 0.9634 - val_recall: 0.9559 - val_auc_pr: 0.9936\n",
      "Epoch 42/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - auc: 0.9900 - loss: 0.1231 - precision: 0.9587 - recall: 0.9494 - val_auc: 0.9927 - val_loss: 0.1049 - val_precision: 0.9654 - val_recall: 0.9548 - val_auc_pr: 0.9937\n",
      "Epoch 43/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1228 - precision: 0.9592 - recall: 0.9490 - val_auc: 0.9926 - val_loss: 0.1058 - val_precision: 0.9675 - val_recall: 0.9514 - val_auc_pr: 0.9936\n",
      "Epoch 44/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1230 - precision: 0.9591 - recall: 0.9485 - val_auc: 0.9926 - val_loss: 0.1058 - val_precision: 0.9640 - val_recall: 0.9551 - val_auc_pr: 0.9936\n",
      "Epoch 45/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1227 - precision: 0.9592 - recall: 0.9494 - val_auc: 0.9926 - val_loss: 0.1076 - val_precision: 0.9702 - val_recall: 0.9463 - val_auc_pr: 0.9936\n",
      "Epoch 46/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1228 - precision: 0.9588 - recall: 0.9490 - val_auc: 0.9927 - val_loss: 0.1052 - val_precision: 0.9651 - val_recall: 0.9546 - val_auc_pr: 0.9936\n",
      "Epoch 47/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1226 - precision: 0.9591 - recall: 0.9498 - val_auc: 0.9927 - val_loss: 0.1060 - val_precision: 0.9677 - val_recall: 0.9503 - val_auc_pr: 0.9936\n",
      "Epoch 48/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1228 - precision: 0.9595 - recall: 0.9492 - val_auc: 0.9927 - val_loss: 0.1052 - val_precision: 0.9662 - val_recall: 0.9528 - val_auc_pr: 0.9936\n",
      "Epoch 49/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9902 - loss: 0.1226 - precision: 0.9591 - recall: 0.9496 - val_auc: 0.9928 - val_loss: 0.1069 - val_precision: 0.9677 - val_recall: 0.9503 - val_auc_pr: 0.9936\n",
      "Epoch 50/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1227 - precision: 0.9589 - recall: 0.9497 - val_auc: 0.9927 - val_loss: 0.1052 - val_precision: 0.9648 - val_recall: 0.9546 - val_auc_pr: 0.9936\n",
      "Epoch 51/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1224 - precision: 0.9593 - recall: 0.9495 - val_auc: 0.9928 - val_loss: 0.1057 - val_precision: 0.9653 - val_recall: 0.9544 - val_auc_pr: 0.9936\n",
      "Epoch 52/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1225 - precision: 0.9586 - recall: 0.9497 - val_auc: 0.9928 - val_loss: 0.1046 - val_precision: 0.9659 - val_recall: 0.9546 - val_auc_pr: 0.9937\n",
      "Epoch 53/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1234 - precision: 0.9588 - recall: 0.9495 - val_auc: 0.9927 - val_loss: 0.1056 - val_precision: 0.9693 - val_recall: 0.9487 - val_auc_pr: 0.9937\n",
      "Epoch 54/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1231 - precision: 0.9594 - recall: 0.9490 - val_auc: 0.9927 - val_loss: 0.1052 - val_precision: 0.9648 - val_recall: 0.9551 - val_auc_pr: 0.9936\n",
      "Epoch 55/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1220 - precision: 0.9591 - recall: 0.9502 - val_auc: 0.9926 - val_loss: 0.1063 - val_precision: 0.9677 - val_recall: 0.9500 - val_auc_pr: 0.9936\n",
      "Epoch 56/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1224 - precision: 0.9586 - recall: 0.9499 - val_auc: 0.9928 - val_loss: 0.1057 - val_precision: 0.9694 - val_recall: 0.9487 - val_auc_pr: 0.9937\n",
      "Epoch 57/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1224 - precision: 0.9592 - recall: 0.9497 - val_auc: 0.9926 - val_loss: 0.1055 - val_precision: 0.9644 - val_recall: 0.9558 - val_auc_pr: 0.9937\n",
      "Epoch 58/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1220 - precision: 0.9588 - recall: 0.9498 - val_auc: 0.9927 - val_loss: 0.1052 - val_precision: 0.9656 - val_recall: 0.9542 - val_auc_pr: 0.9937\n",
      "Epoch 59/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1228 - precision: 0.9595 - recall: 0.9494 - val_auc: 0.9926 - val_loss: 0.1054 - val_precision: 0.9661 - val_recall: 0.9536 - val_auc_pr: 0.9937\n",
      "Epoch 60/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - auc: 0.9902 - loss: 0.1221 - precision: 0.9593 - recall: 0.9501 - val_auc: 0.9925 - val_loss: 0.1063 - val_precision: 0.9648 - val_recall: 0.9551 - val_auc_pr: 0.9936\n",
      "Epoch 61/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - auc: 0.9903 - loss: 0.1217 - precision: 0.9593 - recall: 0.9503 - val_auc: 0.9928 - val_loss: 0.1064 - val_precision: 0.9681 - val_recall: 0.9500 - val_auc_pr: 0.9936\n",
      "Epoch 62/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - auc: 0.9904 - loss: 0.1210 - precision: 0.9598 - recall: 0.9504 - val_auc: 0.9927 - val_loss: 0.1049 - val_precision: 0.9638 - val_recall: 0.9565 - val_auc_pr: 0.9937\n"
     ]
    }
   ],
   "source": [
    "# Train the Model with the Custom Callback\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_resampled, y_train_resampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define early stopping and custom AUC-PR callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "auc_pr_callback = AUC_PR(validation_data=(X_val_split, y_val_split))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_split, y_train_split,\n",
    "    epochs=100,\n",
    "    batch_size=32,    # limit of memory, also the running speed\n",
    "    validation_data=(X_val_split, y_val_split),\n",
    "    callbacks=[early_stopping, auc_pr_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.6.3 Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9315/9315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - auc: 0.8440 - loss: 0.1173 - precision: 0.1058 - recall: 0.3602\n",
      "loss: 0.11628413200378418\n",
      "compile_metrics: 0.1044442430138588\n",
      "\u001b[1m9315/9315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    294800\n",
      "           1       0.10      0.36      0.16      3269\n",
      "\n",
      "    accuracy                           0.96    298069\n",
      "   macro avg       0.55      0.66      0.57    298069\n",
      "weighted avg       0.98      0.96      0.97    298069\n",
      "\n",
      "[[284785  10015]\n",
      " [  2101   1168]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test data\n",
    "results = model.evaluate(X_test, y_test)\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(f\"{name}: {value}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9593516937353431\n",
      "0.10444424573012609\n",
      "0.3572958091159376\n",
      "0.1616385275394409\n",
      "0.8725704481845618\n",
      "0.12528700350742578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(roc_auc_score(y_test, y_score))\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "print(auc(recall, precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop out test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shenj\\miniconda3\\envs\\datascience\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9928\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 3ms/step - auc: 0.9774 - loss: 0.1793 - precision: 0.9339 - recall: 0.9207 - val_auc: 0.9918 - val_loss: 0.1123 - val_precision: 0.9570 - val_recall: 0.9549 - val_auc_pr: 0.9928\n",
      "Epoch 2/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9932\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9903 - loss: 0.1220 - precision: 0.9574 - recall: 0.9487 - val_auc: 0.9924 - val_loss: 0.1089 - val_precision: 0.9552 - val_recall: 0.9609 - val_auc_pr: 0.9932\n",
      "Epoch 3/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9935\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - auc: 0.9909 - loss: 0.1181 - precision: 0.9586 - recall: 0.9511 - val_auc: 0.9927 - val_loss: 0.1058 - val_precision: 0.9576 - val_recall: 0.9607 - val_auc_pr: 0.9935\n",
      "Epoch 4/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9938\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 4ms/step - auc: 0.9912 - loss: 0.1159 - precision: 0.9587 - recall: 0.9533 - val_auc: 0.9930 - val_loss: 0.1042 - val_precision: 0.9602 - val_recall: 0.9599 - val_auc_pr: 0.9938\n",
      "Epoch 5/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 4ms/step - auc: 0.9913 - loss: 0.1148 - precision: 0.9591 - recall: 0.9536 - val_auc: 0.9931 - val_loss: 0.1026 - val_precision: 0.9630 - val_recall: 0.9587 - val_auc_pr: 0.9939\n",
      "Epoch 6/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 4ms/step - auc: 0.9915 - loss: 0.1142 - precision: 0.9591 - recall: 0.9541 - val_auc: 0.9932 - val_loss: 0.1024 - val_precision: 0.9607 - val_recall: 0.9607 - val_auc_pr: 0.9939\n",
      "Epoch 7/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 4ms/step - auc: 0.9915 - loss: 0.1134 - precision: 0.9599 - recall: 0.9538 - val_auc: 0.9932 - val_loss: 0.1026 - val_precision: 0.9648 - val_recall: 0.9575 - val_auc_pr: 0.9940\n",
      "Epoch 8/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 4ms/step - auc: 0.9916 - loss: 0.1128 - precision: 0.9598 - recall: 0.9557 - val_auc: 0.9934 - val_loss: 0.1007 - val_precision: 0.9618 - val_recall: 0.9612 - val_auc_pr: 0.9941\n",
      "Epoch 9/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 5ms/step - auc: 0.9917 - loss: 0.1123 - precision: 0.9597 - recall: 0.9561 - val_auc: 0.9933 - val_loss: 0.1006 - val_precision: 0.9640 - val_recall: 0.9593 - val_auc_pr: 0.9941\n",
      "Epoch 10/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 4ms/step - auc: 0.9918 - loss: 0.1111 - precision: 0.9604 - recall: 0.9563 - val_auc: 0.9935 - val_loss: 0.0996 - val_precision: 0.9633 - val_recall: 0.9606 - val_auc_pr: 0.9942\n",
      "Epoch 11/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 4ms/step - auc: 0.9918 - loss: 0.1108 - precision: 0.9604 - recall: 0.9563 - val_auc: 0.9934 - val_loss: 0.1001 - val_precision: 0.9605 - val_recall: 0.9635 - val_auc_pr: 0.9942\n",
      "Epoch 12/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9943\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 4ms/step - auc: 0.9918 - loss: 0.1110 - precision: 0.9602 - recall: 0.9564 - val_auc: 0.9935 - val_loss: 0.0991 - val_precision: 0.9613 - val_recall: 0.9637 - val_auc_pr: 0.9943\n",
      "Epoch 13/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 4ms/step - auc: 0.9917 - loss: 0.1115 - precision: 0.9603 - recall: 0.9564 - val_auc: 0.9935 - val_loss: 0.0997 - val_precision: 0.9623 - val_recall: 0.9622 - val_auc_pr: 0.9942\n",
      "Epoch 14/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 4ms/step - auc: 0.9920 - loss: 0.1098 - precision: 0.9610 - recall: 0.9568 - val_auc: 0.9934 - val_loss: 0.1003 - val_precision: 0.9589 - val_recall: 0.9647 - val_auc_pr: 0.9942\n",
      "Epoch 15/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9943\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 4ms/step - auc: 0.9921 - loss: 0.1090 - precision: 0.9607 - recall: 0.9576 - val_auc: 0.9935 - val_loss: 0.0990 - val_precision: 0.9643 - val_recall: 0.9613 - val_auc_pr: 0.9943\n",
      "Epoch 16/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9943\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 4ms/step - auc: 0.9920 - loss: 0.1095 - precision: 0.9611 - recall: 0.9573 - val_auc: 0.9935 - val_loss: 0.0989 - val_precision: 0.9638 - val_recall: 0.9619 - val_auc_pr: 0.9943\n",
      "Epoch 17/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9943\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 4ms/step - auc: 0.9921 - loss: 0.1088 - precision: 0.9611 - recall: 0.9578 - val_auc: 0.9934 - val_loss: 0.0989 - val_precision: 0.9641 - val_recall: 0.9612 - val_auc_pr: 0.9943\n",
      "Epoch 18/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3ms/step - auc: 0.9920 - loss: 0.1100 - precision: 0.9610 - recall: 0.9569 - val_auc: 0.9937 - val_loss: 0.0980 - val_precision: 0.9622 - val_recall: 0.9643 - val_auc_pr: 0.9944\n",
      "Epoch 19/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 3ms/step - auc: 0.9920 - loss: 0.1093 - precision: 0.9612 - recall: 0.9571 - val_auc: 0.9937 - val_loss: 0.0985 - val_precision: 0.9628 - val_recall: 0.9632 - val_auc_pr: 0.9944\n",
      "Epoch 20/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1090 - precision: 0.9611 - recall: 0.9573 - val_auc: 0.9937 - val_loss: 0.0987 - val_precision: 0.9654 - val_recall: 0.9599 - val_auc_pr: 0.9944\n",
      "Epoch 21/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 3ms/step - auc: 0.9920 - loss: 0.1094 - precision: 0.9611 - recall: 0.9570 - val_auc: 0.9937 - val_loss: 0.0977 - val_precision: 0.9622 - val_recall: 0.9642 - val_auc_pr: 0.9944\n",
      "Epoch 22/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3ms/step - auc: 0.9920 - loss: 0.1096 - precision: 0.9606 - recall: 0.9573 - val_auc: 0.9937 - val_loss: 0.0981 - val_precision: 0.9636 - val_recall: 0.9632 - val_auc_pr: 0.9944\n",
      "Epoch 23/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1091 - precision: 0.9604 - recall: 0.9580 - val_auc: 0.9937 - val_loss: 0.0974 - val_precision: 0.9629 - val_recall: 0.9646 - val_auc_pr: 0.9944\n",
      "Epoch 24/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 3ms/step - auc: 0.9920 - loss: 0.1094 - precision: 0.9609 - recall: 0.9575 - val_auc: 0.9936 - val_loss: 0.0977 - val_precision: 0.9616 - val_recall: 0.9653 - val_auc_pr: 0.9944\n",
      "Epoch 25/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1082 - precision: 0.9613 - recall: 0.9584 - val_auc: 0.9937 - val_loss: 0.0982 - val_precision: 0.9654 - val_recall: 0.9608 - val_auc_pr: 0.9944\n",
      "Epoch 26/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1087 - precision: 0.9609 - recall: 0.9583 - val_auc: 0.9937 - val_loss: 0.0977 - val_precision: 0.9633 - val_recall: 0.9633 - val_auc_pr: 0.9944\n",
      "Epoch 27/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9944\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 3ms/step - auc: 0.9920 - loss: 0.1096 - precision: 0.9608 - recall: 0.9578 - val_auc: 0.9937 - val_loss: 0.0975 - val_precision: 0.9645 - val_recall: 0.9625 - val_auc_pr: 0.9944\n",
      "Epoch 28/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1082 - precision: 0.9615 - recall: 0.9582 - val_auc: 0.9938 - val_loss: 0.0973 - val_precision: 0.9631 - val_recall: 0.9643 - val_auc_pr: 0.9945\n",
      "Epoch 29/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - auc: 0.9923 - loss: 0.1075 - precision: 0.9614 - recall: 0.9581 - val_auc: 0.9937 - val_loss: 0.0971 - val_precision: 0.9633 - val_recall: 0.9634 - val_auc_pr: 0.9945\n",
      "Epoch 30/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1085 - precision: 0.9610 - recall: 0.9581 - val_auc: 0.9938 - val_loss: 0.0967 - val_precision: 0.9623 - val_recall: 0.9655 - val_auc_pr: 0.9945\n",
      "Epoch 31/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1085 - precision: 0.9616 - recall: 0.9580 - val_auc: 0.9938 - val_loss: 0.0978 - val_precision: 0.9638 - val_recall: 0.9634 - val_auc_pr: 0.9945\n",
      "Epoch 32/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1078 - precision: 0.9618 - recall: 0.9586 - val_auc: 0.9938 - val_loss: 0.0971 - val_precision: 0.9662 - val_recall: 0.9608 - val_auc_pr: 0.9945\n",
      "Epoch 33/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1084 - precision: 0.9614 - recall: 0.9584 - val_auc: 0.9938 - val_loss: 0.0970 - val_precision: 0.9636 - val_recall: 0.9634 - val_auc_pr: 0.9945\n",
      "Epoch 34/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1084 - precision: 0.9616 - recall: 0.9583 - val_auc: 0.9938 - val_loss: 0.0985 - val_precision: 0.9619 - val_recall: 0.9660 - val_auc_pr: 0.9945\n",
      "Epoch 35/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1081 - precision: 0.9615 - recall: 0.9585 - val_auc: 0.9938 - val_loss: 0.0974 - val_precision: 0.9614 - val_recall: 0.9662 - val_auc_pr: 0.9945\n",
      "Epoch 36/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9923 - loss: 0.1077 - precision: 0.9612 - recall: 0.9585 - val_auc: 0.9938 - val_loss: 0.0969 - val_precision: 0.9627 - val_recall: 0.9649 - val_auc_pr: 0.9945\n",
      "Epoch 37/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9923 - loss: 0.1075 - precision: 0.9618 - recall: 0.9583 - val_auc: 0.9938 - val_loss: 0.0971 - val_precision: 0.9654 - val_recall: 0.9619 - val_auc_pr: 0.9945\n",
      "Epoch 38/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1079 - precision: 0.9615 - recall: 0.9585 - val_auc: 0.9937 - val_loss: 0.0967 - val_precision: 0.9643 - val_recall: 0.9625 - val_auc_pr: 0.9945\n",
      "Epoch 39/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1081 - precision: 0.9616 - recall: 0.9585 - val_auc: 0.9937 - val_loss: 0.0961 - val_precision: 0.9642 - val_recall: 0.9647 - val_auc_pr: 0.9945\n",
      "Epoch 40/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 3ms/step - auc: 0.9923 - loss: 0.1075 - precision: 0.9616 - recall: 0.9586 - val_auc: 0.9938 - val_loss: 0.0976 - val_precision: 0.9667 - val_recall: 0.9599 - val_auc_pr: 0.9945\n",
      "Epoch 41/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 3ms/step - auc: 0.9921 - loss: 0.1081 - precision: 0.9614 - recall: 0.9584 - val_auc: 0.9939 - val_loss: 0.0980 - val_precision: 0.9667 - val_recall: 0.9603 - val_auc_pr: 0.9945\n",
      "Epoch 42/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 3ms/step - auc: 0.9923 - loss: 0.1075 - precision: 0.9619 - recall: 0.9583 - val_auc: 0.9938 - val_loss: 0.0985 - val_precision: 0.9690 - val_recall: 0.9576 - val_auc_pr: 0.9945\n",
      "Epoch 43/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1079 - precision: 0.9616 - recall: 0.9580 - val_auc: 0.9938 - val_loss: 0.0965 - val_precision: 0.9631 - val_recall: 0.9645 - val_auc_pr: 0.9945\n",
      "Epoch 44/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9946\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 3ms/step - auc: 0.9923 - loss: 0.1073 - precision: 0.9619 - recall: 0.9589 - val_auc: 0.9939 - val_loss: 0.0976 - val_precision: 0.9680 - val_recall: 0.9593 - val_auc_pr: 0.9946\n",
      "Epoch 45/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 3ms/step - auc: 0.9922 - loss: 0.1084 - precision: 0.9613 - recall: 0.9580 - val_auc: 0.9938 - val_loss: 0.0968 - val_precision: 0.9633 - val_recall: 0.9644 - val_auc_pr: 0.9945\n",
      "Epoch 46/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3ms/step - auc: 0.9923 - loss: 0.1074 - precision: 0.9610 - recall: 0.9587 - val_auc: 0.9938 - val_loss: 0.0967 - val_precision: 0.9629 - val_recall: 0.9650 - val_auc_pr: 0.9945\n",
      "Epoch 47/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2ms/step - auc: 0.9923 - loss: 0.1069 - precision: 0.9624 - recall: 0.9587 - val_auc: 0.9938 - val_loss: 0.0969 - val_precision: 0.9630 - val_recall: 0.9648 - val_auc_pr: 0.9945\n",
      "Epoch 48/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2ms/step - auc: 0.9924 - loss: 0.1067 - precision: 0.9619 - recall: 0.9587 - val_auc: 0.9939 - val_loss: 0.0965 - val_precision: 0.9657 - val_recall: 0.9618 - val_auc_pr: 0.9945\n",
      "Epoch 49/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9945\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2ms/step - auc: 0.9923 - loss: 0.1074 - precision: 0.9617 - recall: 0.9589 - val_auc: 0.9939 - val_loss: 0.0978 - val_precision: 0.9602 - val_recall: 0.9680 - val_auc_pr: 0.9945\n",
      "\u001b[1m9315/9315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - auc: 0.8347 - loss: 0.1176 - precision: 0.1054 - recall: 0.3772\n",
      "loss: 0.11640780419111252\n",
      "compile_metrics: 0.10289252549409866\n",
      "\u001b[1m9315/9315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    294800\n",
      "           1       0.10      0.37      0.16      3269\n",
      "\n",
      "    accuracy                           0.96    298069\n",
      "   macro avg       0.55      0.67      0.57    298069\n",
      "weighted avg       0.98      0.96      0.97    298069\n",
      "\n",
      "[[284224  10576]\n",
      " [  2056   1213]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with precision, recall, and AUC metrics\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[Precision(), Recall(), AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Create a Custom Callback for AUC-PR\n",
    "\n",
    "class AUC_PR(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super(AUC_PR, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "        val_targ = self.validation_data[1]\n",
    "        precision, recall, _ = precision_recall_curve(val_targ, val_predict)\n",
    "        auc_pr = auc(recall, precision)\n",
    "        print(f' - val_auc_pr: {auc_pr:.4f}')\n",
    "        logs['val_auc_pr'] = auc_pr\n",
    "\n",
    "# Train the Model with the Custom Callback\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_resampled, y_train_resampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define early stopping and custom AUC-PR callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "auc_pr_callback = AUC_PR(validation_data=(X_val_split, y_val_split))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_split, y_train_split,\n",
    "    epochs=100,\n",
    "    batch_size=32,    # limit of memory, also the running speed\n",
    "    validation_data=(X_val_split, y_val_split),\n",
    "    callbacks=[early_stopping, auc_pr_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on the test data\n",
    "results = model.evaluate(X_test, y_test)\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(f\"{name}: {value}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    294800\n",
      "           1       0.10      0.37      0.16      3269\n",
      "\n",
      "    accuracy                           0.96    298069\n",
      "   macro avg       0.55      0.67      0.57    298069\n",
      "weighted avg       0.98      0.96      0.97    298069\n",
      "\n",
      "[[284224  10576]\n",
      " [  2056   1213]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 687768), (1, 687768)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shenj\\miniconda3\\envs\\datascience\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9926\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3ms/step - auc: 0.9740 - loss: 0.1939 - precision: 0.9260 - recall: 0.9196 - val_auc: 0.9916 - val_loss: 0.1146 - val_precision: 0.9611 - val_recall: 0.9473 - val_auc_pr: 0.9926\n",
      "Epoch 2/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9929\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - auc: 0.9873 - loss: 0.1396 - precision: 0.9506 - recall: 0.9443 - val_auc: 0.9921 - val_loss: 0.1121 - val_precision: 0.9545 - val_recall: 0.9574 - val_auc_pr: 0.9929\n",
      "Epoch 3/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9931\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3ms/step - auc: 0.9890 - loss: 0.1307 - precision: 0.9539 - recall: 0.9467 - val_auc: 0.9923 - val_loss: 0.1102 - val_precision: 0.9649 - val_recall: 0.9458 - val_auc_pr: 0.9931\n",
      "Epoch 4/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9933\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3ms/step - auc: 0.9893 - loss: 0.1285 - precision: 0.9551 - recall: 0.9477 - val_auc: 0.9925 - val_loss: 0.1087 - val_precision: 0.9528 - val_recall: 0.9617 - val_auc_pr: 0.9933\n",
      "Epoch 5/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9933\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - auc: 0.9898 - loss: 0.1253 - precision: 0.9555 - recall: 0.9492 - val_auc: 0.9925 - val_loss: 0.1079 - val_precision: 0.9594 - val_recall: 0.9552 - val_auc_pr: 0.9933\n",
      "Epoch 6/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9934\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3ms/step - auc: 0.9898 - loss: 0.1252 - precision: 0.9555 - recall: 0.9487 - val_auc: 0.9927 - val_loss: 0.1074 - val_precision: 0.9571 - val_recall: 0.9588 - val_auc_pr: 0.9934\n",
      "Epoch 7/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - auc: 0.9901 - loss: 0.1232 - precision: 0.9564 - recall: 0.9496 - val_auc: 0.9929 - val_loss: 0.1057 - val_precision: 0.9585 - val_recall: 0.9584 - val_auc_pr: 0.9936\n",
      "Epoch 8/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 3ms/step - auc: 0.9904 - loss: 0.1209 - precision: 0.9569 - recall: 0.9511 - val_auc: 0.9930 - val_loss: 0.1051 - val_precision: 0.9587 - val_recall: 0.9588 - val_auc_pr: 0.9937\n",
      "Epoch 9/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9936\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3ms/step - auc: 0.9904 - loss: 0.1214 - precision: 0.9564 - recall: 0.9505 - val_auc: 0.9929 - val_loss: 0.1060 - val_precision: 0.9581 - val_recall: 0.9596 - val_auc_pr: 0.9936\n",
      "Epoch 10/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 3ms/step - auc: 0.9904 - loss: 0.1212 - precision: 0.9565 - recall: 0.9513 - val_auc: 0.9930 - val_loss: 0.1061 - val_precision: 0.9547 - val_recall: 0.9635 - val_auc_pr: 0.9937\n",
      "Epoch 11/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3ms/step - auc: 0.9905 - loss: 0.1204 - precision: 0.9575 - recall: 0.9512 - val_auc: 0.9930 - val_loss: 0.1045 - val_precision: 0.9580 - val_recall: 0.9602 - val_auc_pr: 0.9937\n",
      "Epoch 12/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9938\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - auc: 0.9905 - loss: 0.1204 - precision: 0.9568 - recall: 0.9516 - val_auc: 0.9931 - val_loss: 0.1040 - val_precision: 0.9572 - val_recall: 0.9621 - val_auc_pr: 0.9938\n",
      "Epoch 13/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9937\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3ms/step - auc: 0.9905 - loss: 0.1204 - precision: 0.9568 - recall: 0.9512 - val_auc: 0.9931 - val_loss: 0.1044 - val_precision: 0.9606 - val_recall: 0.9582 - val_auc_pr: 0.9937\n",
      "Epoch 14/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9938\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 3ms/step - auc: 0.9906 - loss: 0.1195 - precision: 0.9571 - recall: 0.9517 - val_auc: 0.9931 - val_loss: 0.1036 - val_precision: 0.9588 - val_recall: 0.9608 - val_auc_pr: 0.9938\n",
      "Epoch 15/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9938\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3ms/step - auc: 0.9906 - loss: 0.1197 - precision: 0.9571 - recall: 0.9522 - val_auc: 0.9932 - val_loss: 0.1036 - val_precision: 0.9609 - val_recall: 0.9589 - val_auc_pr: 0.9938\n",
      "Epoch 16/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - auc: 0.9907 - loss: 0.1190 - precision: 0.9573 - recall: 0.9519 - val_auc: 0.9932 - val_loss: 0.1027 - val_precision: 0.9616 - val_recall: 0.9585 - val_auc_pr: 0.9939\n",
      "Epoch 17/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3ms/step - auc: 0.9908 - loss: 0.1189 - precision: 0.9573 - recall: 0.9520 - val_auc: 0.9932 - val_loss: 0.1032 - val_precision: 0.9611 - val_recall: 0.9591 - val_auc_pr: 0.9939\n",
      "Epoch 18/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3ms/step - auc: 0.9907 - loss: 0.1193 - precision: 0.9571 - recall: 0.9520 - val_auc: 0.9932 - val_loss: 0.1035 - val_precision: 0.9552 - val_recall: 0.9639 - val_auc_pr: 0.9939\n",
      "Epoch 19/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3ms/step - auc: 0.9908 - loss: 0.1187 - precision: 0.9566 - recall: 0.9523 - val_auc: 0.9933 - val_loss: 0.1027 - val_precision: 0.9579 - val_recall: 0.9628 - val_auc_pr: 0.9939\n",
      "Epoch 20/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3ms/step - auc: 0.9908 - loss: 0.1182 - precision: 0.9577 - recall: 0.9523 - val_auc: 0.9932 - val_loss: 0.1030 - val_precision: 0.9578 - val_recall: 0.9622 - val_auc_pr: 0.9939\n",
      "Epoch 21/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3ms/step - auc: 0.9910 - loss: 0.1173 - precision: 0.9576 - recall: 0.9525 - val_auc: 0.9933 - val_loss: 0.1033 - val_precision: 0.9630 - val_recall: 0.9577 - val_auc_pr: 0.9940\n",
      "Epoch 22/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - auc: 0.9909 - loss: 0.1180 - precision: 0.9572 - recall: 0.9522 - val_auc: 0.9933 - val_loss: 0.1035 - val_precision: 0.9537 - val_recall: 0.9664 - val_auc_pr: 0.9940\n",
      "Epoch 23/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - auc: 0.9908 - loss: 0.1182 - precision: 0.9575 - recall: 0.9520 - val_auc: 0.9933 - val_loss: 0.1027 - val_precision: 0.9583 - val_recall: 0.9626 - val_auc_pr: 0.9939\n",
      "Epoch 24/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9939\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - auc: 0.9910 - loss: 0.1175 - precision: 0.9578 - recall: 0.9532 - val_auc: 0.9933 - val_loss: 0.1042 - val_precision: 0.9588 - val_recall: 0.9613 - val_auc_pr: 0.9939\n",
      "Epoch 25/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - auc: 0.9909 - loss: 0.1177 - precision: 0.9573 - recall: 0.9532 - val_auc: 0.9933 - val_loss: 0.1025 - val_precision: 0.9634 - val_recall: 0.9571 - val_auc_pr: 0.9940\n",
      "Epoch 26/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - auc: 0.9910 - loss: 0.1171 - precision: 0.9581 - recall: 0.9530 - val_auc: 0.9934 - val_loss: 0.1017 - val_precision: 0.9577 - val_recall: 0.9640 - val_auc_pr: 0.9940\n",
      "Epoch 27/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9910 - loss: 0.1175 - precision: 0.9575 - recall: 0.9528 - val_auc: 0.9934 - val_loss: 0.1016 - val_precision: 0.9612 - val_recall: 0.9597 - val_auc_pr: 0.9940\n",
      "Epoch 28/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1166 - precision: 0.9578 - recall: 0.9535 - val_auc: 0.9933 - val_loss: 0.1016 - val_precision: 0.9614 - val_recall: 0.9599 - val_auc_pr: 0.9940\n",
      "Epoch 29/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - auc: 0.9911 - loss: 0.1165 - precision: 0.9579 - recall: 0.9535 - val_auc: 0.9934 - val_loss: 0.1015 - val_precision: 0.9580 - val_recall: 0.9631 - val_auc_pr: 0.9940\n",
      "Epoch 30/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1169 - precision: 0.9580 - recall: 0.9534 - val_auc: 0.9934 - val_loss: 0.1023 - val_precision: 0.9666 - val_recall: 0.9535 - val_auc_pr: 0.9940\n",
      "Epoch 31/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9910 - loss: 0.1165 - precision: 0.9584 - recall: 0.9533 - val_auc: 0.9934 - val_loss: 0.1009 - val_precision: 0.9622 - val_recall: 0.9591 - val_auc_pr: 0.9941\n",
      "Epoch 32/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9910 - loss: 0.1171 - precision: 0.9576 - recall: 0.9530 - val_auc: 0.9934 - val_loss: 0.1033 - val_precision: 0.9569 - val_recall: 0.9645 - val_auc_pr: 0.9940\n",
      "Epoch 33/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - auc: 0.9910 - loss: 0.1164 - precision: 0.9579 - recall: 0.9538 - val_auc: 0.9935 - val_loss: 0.1007 - val_precision: 0.9604 - val_recall: 0.9616 - val_auc_pr: 0.9941\n",
      "Epoch 34/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1164 - precision: 0.9581 - recall: 0.9533 - val_auc: 0.9935 - val_loss: 0.1005 - val_precision: 0.9594 - val_recall: 0.9629 - val_auc_pr: 0.9941\n",
      "Epoch 35/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9940\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1165 - precision: 0.9577 - recall: 0.9538 - val_auc: 0.9934 - val_loss: 0.1017 - val_precision: 0.9581 - val_recall: 0.9624 - val_auc_pr: 0.9940\n",
      "Epoch 36/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1158 - precision: 0.9577 - recall: 0.9537 - val_auc: 0.9935 - val_loss: 0.1006 - val_precision: 0.9586 - val_recall: 0.9634 - val_auc_pr: 0.9941\n",
      "Epoch 37/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1166 - precision: 0.9577 - recall: 0.9537 - val_auc: 0.9935 - val_loss: 0.1006 - val_precision: 0.9581 - val_recall: 0.9642 - val_auc_pr: 0.9941\n",
      "Epoch 38/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9910 - loss: 0.1169 - precision: 0.9576 - recall: 0.9530 - val_auc: 0.9935 - val_loss: 0.1005 - val_precision: 0.9602 - val_recall: 0.9622 - val_auc_pr: 0.9941\n",
      "Epoch 39/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1166 - precision: 0.9582 - recall: 0.9528 - val_auc: 0.9935 - val_loss: 0.1009 - val_precision: 0.9596 - val_recall: 0.9626 - val_auc_pr: 0.9941\n",
      "Epoch 40/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1157 - precision: 0.9585 - recall: 0.9534 - val_auc: 0.9935 - val_loss: 0.1013 - val_precision: 0.9606 - val_recall: 0.9614 - val_auc_pr: 0.9941\n",
      "Epoch 41/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1160 - precision: 0.9578 - recall: 0.9536 - val_auc: 0.9934 - val_loss: 0.1007 - val_precision: 0.9599 - val_recall: 0.9626 - val_auc_pr: 0.9941\n",
      "Epoch 42/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - auc: 0.9912 - loss: 0.1160 - precision: 0.9577 - recall: 0.9536 - val_auc: 0.9935 - val_loss: 0.1006 - val_precision: 0.9594 - val_recall: 0.9634 - val_auc_pr: 0.9941\n",
      "Epoch 43/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1156 - precision: 0.9585 - recall: 0.9538 - val_auc: 0.9935 - val_loss: 0.1005 - val_precision: 0.9609 - val_recall: 0.9607 - val_auc_pr: 0.9941\n",
      "Epoch 44/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1166 - precision: 0.9574 - recall: 0.9537 - val_auc: 0.9935 - val_loss: 0.1003 - val_precision: 0.9605 - val_recall: 0.9623 - val_auc_pr: 0.9941\n",
      "Epoch 45/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1154 - precision: 0.9583 - recall: 0.9539 - val_auc: 0.9936 - val_loss: 0.1004 - val_precision: 0.9617 - val_recall: 0.9613 - val_auc_pr: 0.9942\n",
      "Epoch 46/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9911 - loss: 0.1160 - precision: 0.9582 - recall: 0.9539 - val_auc: 0.9936 - val_loss: 0.1008 - val_precision: 0.9591 - val_recall: 0.9635 - val_auc_pr: 0.9942\n",
      "Epoch 47/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1156 - precision: 0.9579 - recall: 0.9541 - val_auc: 0.9936 - val_loss: 0.1006 - val_precision: 0.9596 - val_recall: 0.9634 - val_auc_pr: 0.9942\n",
      "Epoch 48/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9913 - loss: 0.1154 - precision: 0.9579 - recall: 0.9540 - val_auc: 0.9936 - val_loss: 0.1004 - val_precision: 0.9598 - val_recall: 0.9636 - val_auc_pr: 0.9942\n",
      "Epoch 49/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9913 - loss: 0.1149 - precision: 0.9583 - recall: 0.9535 - val_auc: 0.9936 - val_loss: 0.1008 - val_precision: 0.9629 - val_recall: 0.9595 - val_auc_pr: 0.9942\n",
      "Epoch 50/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9941\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9913 - loss: 0.1152 - precision: 0.9578 - recall: 0.9541 - val_auc: 0.9935 - val_loss: 0.1007 - val_precision: 0.9574 - val_recall: 0.9651 - val_auc_pr: 0.9941\n",
      "Epoch 51/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - auc: 0.9913 - loss: 0.1148 - precision: 0.9580 - recall: 0.9547 - val_auc: 0.9936 - val_loss: 0.0993 - val_precision: 0.9616 - val_recall: 0.9619 - val_auc_pr: 0.9942\n",
      "Epoch 52/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - auc: 0.9911 - loss: 0.1161 - precision: 0.9579 - recall: 0.9536 - val_auc: 0.9935 - val_loss: 0.1005 - val_precision: 0.9611 - val_recall: 0.9613 - val_auc_pr: 0.9942\n",
      "Epoch 53/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1158 - precision: 0.9581 - recall: 0.9537 - val_auc: 0.9935 - val_loss: 0.1004 - val_precision: 0.9600 - val_recall: 0.9628 - val_auc_pr: 0.9942\n",
      "Epoch 54/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9913 - loss: 0.1153 - precision: 0.9579 - recall: 0.9542 - val_auc: 0.9935 - val_loss: 0.1002 - val_precision: 0.9603 - val_recall: 0.9628 - val_auc_pr: 0.9942\n",
      "Epoch 55/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9913 - loss: 0.1154 - precision: 0.9578 - recall: 0.9545 - val_auc: 0.9936 - val_loss: 0.1001 - val_precision: 0.9656 - val_recall: 0.9564 - val_auc_pr: 0.9942\n",
      "Epoch 56/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - auc: 0.9912 - loss: 0.1156 - precision: 0.9582 - recall: 0.9540 - val_auc: 0.9936 - val_loss: 0.0997 - val_precision: 0.9624 - val_recall: 0.9604 - val_auc_pr: 0.9942\n",
      "Epoch 57/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - auc: 0.9913 - loss: 0.1149 - precision: 0.9583 - recall: 0.9546 - val_auc: 0.9936 - val_loss: 0.0996 - val_precision: 0.9625 - val_recall: 0.9609 - val_auc_pr: 0.9942\n",
      "Epoch 58/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - auc: 0.9913 - loss: 0.1152 - precision: 0.9584 - recall: 0.9543 - val_auc: 0.9936 - val_loss: 0.0994 - val_precision: 0.9612 - val_recall: 0.9623 - val_auc_pr: 0.9942\n",
      "Epoch 59/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - auc: 0.9913 - loss: 0.1152 - precision: 0.9583 - recall: 0.9544 - val_auc: 0.9936 - val_loss: 0.0995 - val_precision: 0.9638 - val_recall: 0.9597 - val_auc_pr: 0.9942\n",
      "Epoch 60/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - auc: 0.9913 - loss: 0.1147 - precision: 0.9587 - recall: 0.9543 - val_auc: 0.9935 - val_loss: 0.0999 - val_precision: 0.9646 - val_recall: 0.9586 - val_auc_pr: 0.9942\n",
      "Epoch 61/100\n",
      "\u001b[1m8598/8598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      " - val_auc_pr: 0.9942\n",
      "\u001b[1m34389/34389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3ms/step - auc: 0.9914 - loss: 0.1146 - precision: 0.9583 - recall: 0.9547 - val_auc: 0.9936 - val_loss: 0.0996 - val_precision: 0.9608 - val_recall: 0.9625 - val_auc_pr: 0.9942\n",
      "\u001b[1m9315/9315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - auc: 0.8427 - loss: 0.1168 - precision: 0.0997 - recall: 0.3789\n",
      "loss: 0.11602653563022614\n",
      "compile_metrics: 0.09824926406145096\n",
      "\u001b[1m9315/9315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98    294800\n",
      "           1       0.10      0.38      0.16      3269\n",
      "\n",
      "    accuracy                           0.96    298069\n",
      "   macro avg       0.55      0.67      0.57    298069\n",
      "weighted avg       0.98      0.96      0.97    298069\n",
      "\n",
      "[[283520  11280]\n",
      " [  2040   1229]]\n",
      "0.9553123605608097\n",
      "0.09824926053241666\n",
      "0.37595594983175284\n",
      "0.15578653821777158\n",
      "0.8725704481845618\n",
      "0.12528700350742578\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_train_resampled).items()))\n",
    "\n",
    "#---------------------------------------------\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with precision, recall, and AUC metrics\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[Precision(), Recall(), AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Create a Custom Callback for AUC-PR\n",
    "\n",
    "class AUC_PR(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super(AUC_PR, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "        val_targ = self.validation_data[1]\n",
    "        precision, recall, _ = precision_recall_curve(val_targ, val_predict)\n",
    "        auc_pr = auc(recall, precision)\n",
    "        print(f' - val_auc_pr: {auc_pr:.4f}')\n",
    "        logs['val_auc_pr'] = auc_pr\n",
    "\n",
    "# Train the Model with the Custom Callback\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_resampled, y_train_resampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define early stopping and custom AUC-PR callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "auc_pr_callback = AUC_PR(validation_data=(X_val_split, y_val_split))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_split, y_train_split,\n",
    "    epochs=100,\n",
    "    batch_size=32,    # limit of memory, also the running speed\n",
    "    validation_data=(X_val_split, y_val_split),\n",
    "    callbacks=[early_stopping, auc_pr_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on the test data\n",
    "results = model.evaluate(X_test, y_test)\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(f\"{name}: {value}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#--------------------------------------\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(roc_auc_score(y_test, y_score))\n",
    "\n",
    "# Compute the precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "# Compute the area under precision-recall curve (pr_auc)\n",
    "print(auc(recall, precision))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
